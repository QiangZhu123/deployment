{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "246532b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_7608\\3777615979.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a26fc41",
   "metadata": {},
   "source": [
    "# Api\n",
    "   #### base\n",
    "    导出中间格式文件的函数，以onnx和torchsrtipt为目标\n",
    "    export:主要是对torch.onnx.export函数的装饰，增加了模型以及函数的替换工作，就是mmdeploy的主要任务\n",
    "    extract_partition：对给定模型进行切分的工作\n",
    "    from_onnx:由onnx转化为后端，有些后端没有\n",
    "    同样，在torchscript中也对torch.jit.trace函数进行了装饰，增加了一样的工作流程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c476d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdeploy.apis.onnx import export,extract_partition\n",
    "from mmdeploy.apis.torch_jit import trace\n",
    "model = create_model()\n",
    "args = get_input_tensor()\n",
    "\n",
    "#主函数\n",
    "export(model, args,\n",
    "    'place/to/save/model',\n",
    "    backend='tensorrt',\n",
    "    input_names=['input'],output_names=['output'],\n",
    "    dynamic_axes={'input': {\n",
    "    0: 'batch',\n",
    "    2: 'height',\n",
    "     3: 'width'\n",
    "        }})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65742fbe",
   "metadata": {},
   "source": [
    "# backend 独立模块\n",
    "   #### base\n",
    "    后端管理器，需要功能 1. 将中间文件转化为后端文件，2.创建执行后端格式的模型\n",
    "\n",
    "    1.BaseBackendManager继承后，实现to_backend 类方法（主函数），就是把中间文件转化为后端文件类型函数\n",
    "    一般中间文件是onnx格式的，那就需要写一个from_onnx函数，将onnx文件转化为后端文件，并在这里调用  \n",
    "\n",
    "    2.BaseWrapper是后端模型执行的抽象类，载入后端模型，为了让后端模型能够使用，需要加入forward函数的重写。\n",
    "\n",
    "    最后，可能会有特有的后端库函数编译文件，也需要在这个包中实现加载。\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dc3607",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdeploy.backend.base import BaseBackendManager,get_backend_manager,BaseWrapper\n",
    "from mmdeploy.backend.onnxruntime import ORTWrapper\n",
    "import torch\n",
    "from mmengine.model import revert_sync_batchnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2cc1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_file = 'model.onnx'\n",
    "model = ORTWrapper(onnx_file, 'cpu')\n",
    "inputs = dict(input=torch.randn(1, 3, 224, 224, device='cpu'))\n",
    "outputs = model(inputs)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c06921e",
   "metadata": {},
   "source": [
    "# codebase 导入模块和创建Task（只需要注册继承）\n",
    "   #### base文件--》import_codebase\n",
    "     BaseBackendModel：后端模型的基类，这是一个中间接口，用来创建一个带有wrapper的后端模型\n",
    "     MMCodebase:\n",
    "         负责导入模型包，和创建Task类\n",
    "            get_task_class：根据任务类型获得类\n",
    "            build_task_processor：根据给定config,构建相应的任务Task类\n",
    "            register_deploy_modules：（重写）\n",
    "                import 该任务对应的models重写函数部分模块ie. mmdeploy.mmpretrain.models  \n",
    "            register_all_modules：（重写）\n",
    "                import 相应任务的所有模块包文件ie . mmpretrain\n",
    "    BaseTask：\n",
    "         根据给定的config,导入模型文件，并实例化模型，数据集等用于执行的组件，类似于runner\n",
    "         有抽象方法需要实现。因为任务不同，所以构建组件的形式可能不同，需要重写\n",
    "             \n",
    "####  mm任务\n",
    "    deploy：\n",
    "        需要实现该任务对BaseTask ，MMCodebase和BaseBackendModel特定继承类\n",
    "        MMCodebase:导入包，创建对应的Task实例\n",
    "        BaseTask:整个任务的全流程\n",
    "        BaseBackendModel：这个是对后端任务的模型的再包装，后端模型是需要让后端文件执行，\n",
    "            但是还需要对输入进行预处理，这部分并不在模型中，所以需要外面处理好再给后端模型，\n",
    "            所以这个模型是包括对输入的预处理和输出的预处理两个部分，同时本身还是一个nn.module\n",
    "        \n",
    "    models:\n",
    "        from mmdeploy.core import FUNCTION_REWRITER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68040f5c",
   "metadata": {},
   "source": [
    "# core：\n",
    "    这里就是mmdeploy替换模型的原理模块，使用替换的形式修改模型\n",
    "      rewriter:\n",
    "        RewriterRegistry：注册器\n",
    "        RewriterManager：管理器\n",
    "            分为function，module，symblic三个rewriter类\n",
    "            FunctionRewriter：\n",
    "                内部有个注册表，原理就是在执行模型的时候，将模型的函数，替换成设置的函数即可\n",
    "            SymbolicRewriter：\n",
    "                这个就是原来的Symbolic函数的写法\n",
    "        RewriterContext，里面有一个RewriterManager管理器，用with 方式打开，后对function和symblic执行替换，而对于module，则要一个函数patch_model来执行替换\n",
    "        \n",
    "            @FUNCTION_REWRITER.register_rewriter(func_name='mmpretrain.models.backbones.shufflenet_v2.InvertedResidual.forward')\n",
    "        def shufflenetv2_backbone__forward__default(self, x):\n",
    "             return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc5b726",
   "metadata": {},
   "source": [
    "# mmcv\n",
    "    这里是专门给MMCV一些函数的替换\n",
    "# pytorch\n",
    "\n",
    "      这里是一些需要替换的torch函数，用的都是\n",
    "\n",
    "      @FUNCTION_REWRITER.register_rewriter(func_name='torch.Tensor.flatten', backend=Backend.NCNN.value)\n",
    "      def myfunc():\n",
    "          return tensor\n",
    "      只有两种，一种是函数替换，一种是符号替换。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6336d247",
   "metadata": {},
   "source": [
    "# 具体的调用过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236234fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "在tool中有delpoy.py函数，需要给定deploy_config,model_config,checkpoint,img参数\n",
    "\n",
    "主要做三项工作，torch2onnx（转onnx，或者torchscript）,extract_model(抽取模型),create_calib_input_data（量化数据集）\n",
    "\n",
    "先转化为中间格式torch2onnx\n",
    "torch2onnx：载入所有参数文件，用build_task_processor函数，实例化CodeBase类进行任务包的导入，然后调用MMCodebase.build_task_processor方法,\n",
    "            创建一个任务处理器，那就可以用任务处理器创建所有的组件，比如创建输入，创建模型MODEL.build()。之后就会调用export函\n",
    "            数，在函数中，需要完成对模型函数的替换工作（Core），最后调用torch.onnx.epxort生成onnx的文件。\n",
    "        \n",
    "再转化为后端文件\n",
    "to_backend:就是将中间文件ONNX转化为对应后端文件的函数。创建BaseBackendManager调用BaseBackendManager里面的to_backend函数。\n",
    "            不同框架的转化方式不同。\n",
    "        \n",
    "最后，可以对后端模型和pyorch模型进行结果可视化对比，这个过程也是用Task的完成的，需要BaseBackendManager让每个框架实现\n",
    "带有forward函数的wrapper模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7c6289",
   "metadata": {},
   "source": [
    "# 使用方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4a0bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#toonnx\n",
    "from mmdeploy.apis import torch2onnx\n",
    "img = 'demo.jpg'\n",
    "work_dir = 'work_dir'\n",
    "save_file ='fcos.onnx'\n",
    "deploy_cfg = ('configs/mmdet/detection/detection_onnxruntime_dynamic.py')\n",
    "model_cfg = ('mmdetection/configs/fcos/fcos_r50_caffe_fpn_gn-head_1x_coco.py')\n",
    "model_checkpoint = ('checkpoints/fcos_r50_caffe_fpn_gn-head_1x_coco-821213aa.pth')\n",
    "device = 'cpu'\n",
    "\n",
    "# from mmengine.registry import MODELS\n",
    "#模型参数想要能使用下面的方法，必须是可以MODELS.build的类型，也就是说必须进行注册\n",
    "torch2onnx(img,#图片\n",
    "           work_dir,#保存路径\n",
    "           save_file,#ir文件名\n",
    "           deploy_cfg,\n",
    "           model_cfg,\n",
    "           model_checkpoint,\n",
    "           device#  'cpu'\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502e2131",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tobackend，不同的后端可能会与onnx2backend这样的函数包装from_onnx函数\n",
    "from mmdeploy.backend.tensorrt import from_onnx\n",
    "\n",
    "from_onnx(\n",
    "    onnx_path,\n",
    "    output_prefix,\n",
    "    input_shapes=final_params['input_shapes'],\n",
    "    log_level=get_trt_log_level(),\n",
    "    fp16_mode=final_params.get('fp16_mode', False),\n",
    "    int8_mode=final_params.get('int8_mode', False),\n",
    "    int8_param=int8_param,\n",
    "    max_workspace_size=final_params.get('max_workspace_size', 0),\n",
    "    device_id=device_id)\n",
    "\n",
    "from mmdeploy.backend.onnxruntime import ONNXRuntimeManager\n",
    "\n",
    "backendfile = ONNXRuntimeManager.to_backend(ir_files: Sequence[str],\n",
    "                   work_dir: str,\n",
    "                   log_level: int = logging.INFO,\n",
    "                   device: str = 'cpu',)\n",
    "\n",
    "\n",
    "#这只是后端模型，还需要对输入预处理才能正确使用，所以一般使用再装饰的模型\n",
    "backendmodel = ONNXRuntimeManager.build_wrapper(backend_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b0f018",
   "metadata": {},
   "outputs": [],
   "source": [
    "#这个东西很关键，直接给定参数，他会自动导入任务包，实例化出对应的模型\n",
    "from mmdeploy.apis.utils import build_task_processor\n",
    "task_processor = build_task_processor(model_cfg,#Config类\n",
    "                                      deploy_cfg,#Config类\n",
    "                                      device)\n",
    "\n",
    "\n",
    "#这个就是后端模型\n",
    "model = task_processor.build_backend_model(['/root/work_dir/FCOS.onnx'], \n",
    "                                        data_preprocessor_updater=task_processor.update_data_preprocessor)\n",
    "input_shape = get_input_shape(deploy_cfg)\n",
    "model_inputs, _ = task_processor.create_input(img, input_shape)\n",
    "with torch.no_grad():\n",
    "    result = model.test_step(model_inputs)[0]\n",
    "    \n",
    "task_processor.visualize(\n",
    "    image=img,\n",
    "    model=model,\n",
    "    result=result,\n",
    "    output_file='/root/test.jpg',\n",
    "    window_name='test',\n",
    "    show_result=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204a3aba",
   "metadata": {},
   "source": [
    "# 备注"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4ab25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_cfg\n",
    "backend_config = dict(type='coreml', convert_to='mlprogram')#后端名称\n",
    "onnx_config = dict(type='onnx',\n",
    "    export_params=True,keep_initializers_as_inputs=False,\n",
    "    opset_version=11, save_file='end2end.onnx',\n",
    "                    input_names=['input'], \n",
    "                   output_names=['output'],\n",
    "                   input_shape=None,#输入大小\n",
    "                   optimize=True)#中间格式\n",
    "codebase_config = dict(type='mmpretrain', task='Classification')#codebase的名称"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b575bc",
   "metadata": {},
   "source": [
    "# 检查模型是否正确"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb788f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdeploy.apis import visualize_model\n",
    "from mmdeploy.utils import Backend\n",
    "\n",
    "model_cfg = 'mmdetection/configs/fcos/fcos_r50_caffe_fpn_gn-head_1x_coco.py'\n",
    "deploy_cfg = 'configs/mmdet/detection/detection_onnxruntime_dynamic.py'\n",
    "model = 'work_dir/fcos.onnx'\n",
    "img = 'demo.jpg'\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea1e048",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(model_cfg,deploy_cfg,[checkpoint],img,'cpu',\n",
    "                Backend.PYTORCH,\n",
    "                show_result=True,output_file='/root/out.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be355a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(model_cfg,deploy_cfg,'/root/work_dir/FCOS.onnx',img,'cpu',\n",
    "                Backend.ONNXRUNTIME,\n",
    "                show_result=True,output_file='/root/out-onnx.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ba81c3",
   "metadata": {},
   "source": [
    "# 量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7bd441",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/nihui/imagenet-sample-images --depth=1\n",
    "python3 tools/deploy.py  configs/mmpretrain/classification_ncnn-int8_static.py \n",
    "${MODEL_CONFIG}  \n",
    "${MODEL_PATH} \n",
    "/path/to/self-test.png  \n",
    "--work-dir work_dir \n",
    "--device cpu \n",
    "--quant \n",
    "--quant-image-dir /path/to/imagenet-sample-images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba33a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b4d924",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
