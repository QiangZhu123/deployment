{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnx import *\n",
    "from onnx import shape_inference\n",
    "import numpy as np\n",
    "#make model\n",
    "import torch\n",
    "from onnx import AttributeProto, TensorProto, GraphProto\n",
    "from torch.onnx.utils import register_custom_op_symbolic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Float attribute:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'pi = 3.14000010490417'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#制作属性\n",
    "arg = helper.make_attribute(\"pi\", 3.14)\n",
    "print(\"\\nFloat attribute:\\n\")\n",
    "\n",
    "#用里面自带的print函数来显示\n",
    "helper.printable_attribute(arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%Y = Conv[kernel = 3, pad = 1, stride = 1](%X, %W, %B)\n"
     ]
    }
   ],
   "source": [
    "#制作一个节点\n",
    "#     output  = op_name [i,i,i,i](input)\n",
    "#格式 “Y”  = \"Conv\" [attribut1,attribut2,attribut3](\"X\",'Y','B')\n",
    "node_proto = helper.make_node(\n",
    "    \"Conv\",#要是onnx支持的操作符，不然不行\n",
    "    [\"X\", \"W\", \"B\"],#输入命名\n",
    "    [\"Y\"],#输出\n",
    "    name='conv1',#给操作命名\n",
    "    kernel=3, stride=1, pad=1)#其他参数\n",
    "print(helper.printable_node(node_proto))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"kernel\"\n",
       "i: 3\n",
       "type: INT"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_proto.attribute[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"kernel\"\n",
      "i: 3\n",
      "type: INT\n",
      ", name: \"pad\"\n",
      "i: 1\n",
      "type: INT\n",
      ", name: \"stride\"\n",
      "i: 1\n",
      "type: INT\n",
      "]\n",
      "%Y = Conv[kernel = 3, pad = 15, stride = 2](%X, %W, %B)\n"
     ]
    }
   ],
   "source": [
    "#查看参数\n",
    "print(node_proto.attribute)#列表保存所有的参数\n",
    "#这是一个列表，可进行参数修改,也就是可以遍历改变属性\n",
    "node_proto.attribute[1].i = 15\n",
    "node_proto.attribute[2].i = 2\n",
    "print(helper.printable_node(node_proto))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "graph proto:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'graph MLP (\\n  %X[FLOAT, 1]\\n  %W1[FLOAT, 1]\\n  %B1[FLOAT, 1]\\n  %W2[FLOAT, 1]\\n  %B2[FLOAT, 1]\\n) initializers (\\n  %Pads[INT64, 4]\\n) {\\n  %H1 = FC(%X, %W1, %B1)\\n  %R1 = Relu(%H1)\\n  %B = Conv(%X)\\n  %Y = FC(%R1, %W2, %B2)\\n  return %Y\\n}'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#观察完整图的构建，([节点，节点，..],名称,[输入节点信息,输入节点信息,输入节点信息,...],[输出节点信息是最后一个,不是中间节点],[写一个输入])\n",
    "graph_proto = helper.make_graph(\n",
    "    [\n",
    "        helper.make_node(\"FC\", [\"X\", \"W1\", \"B1\"], [\"H1\"]),\n",
    "        helper.make_node(\"Relu\", [\"H1\"], [\"R1\"]),\n",
    "        helper.make_node(\"Conv\",[\"X\"],[\"B\"]),\n",
    "        helper.make_node(\"FC\", [\"R1\", \"W2\", \"B2\"], [\"Y\"]),\n",
    "        \n",
    "    ],\n",
    "    \"MLP\",\n",
    "    [\n",
    "        helper.make_tensor_value_info('X', TensorProto.FLOAT, [1]),\n",
    "        helper.make_tensor_value_info('W1', TensorProto.FLOAT, [1]),\n",
    "        helper.make_tensor_value_info('B1', TensorProto.FLOAT, [1]),\n",
    "        helper.make_tensor_value_info('W2', TensorProto.FLOAT, [1]),\n",
    "        helper.make_tensor_value_info('B2', TensorProto.FLOAT, [1]),\n",
    "    ],\n",
    "    [\n",
    "        helper.make_tensor_value_info('Y', TensorProto.FLOAT, [1]),\n",
    "    ],\n",
    "    [helper.make_tensor('Pads', TensorProto.INT64, [4,], [0, 0, 1, 1,])],\n",
    ")\n",
    "model = helper.make_model(graph_proto)\n",
    "print(\"\\ngraph proto:\\n\")\n",
    "helper.printable_graph(graph_proto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[dims: 4\n",
       "data_type: 7\n",
       "int64_data: 0\n",
       "int64_data: 0\n",
       "int64_data: 1\n",
       "int64_data: 1\n",
       "name: \"Pads\"\n",
       "]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查看图中的不同信息\n",
    "#graph_proto.node\n",
    "#graph_proto.input\n",
    "#graph_proto.output\n",
    "graph_proto.initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one input (ValueInfoProto)\n",
    "X = helper.make_tensor_value_info('X', TensorProto.FLOAT, [1, 2])\n",
    "\n",
    "# Create second input (ValueInfoProto)\n",
    "Pads = helper.make_tensor_value_info('Pads', TensorProto.INT64, [4])\n",
    "\n",
    "# Create one output (ValueInfoProto)\n",
    "Y = helper.make_tensor_value_info('Y', TensorProto.FLOAT, [1, 4])\n",
    "\n",
    "# Create a node (NodeProto)\n",
    "node_def = helper.make_node(\n",
    "    'Pad', # node name\n",
    "    ['X', 'Pads'], # inputs\n",
    "    ['Y'], # outputs\n",
    "    mode='constant', # Attributes\n",
    ")\n",
    "\n",
    "# Create the graph (GraphProto)\n",
    "graph_def = helper.make_graph(\n",
    "    [node_def],\n",
    "    \"test-model\",\n",
    "    [X, Pads],\n",
    "    [Y],\n",
    "    [helper.make_tensor('Pads', TensorProto.INT64, [4,], [0, 0, 1, 1,])],\n",
    ")\n",
    "\n",
    "# 要把图做成模型才能导出\n",
    "model_def = helper.make_model(graph_def,\n",
    "                              producer_name='onnx-example')\n",
    "\n",
    "#print('The producer_name in model: {}\\n'.format(model_def.producer_name))\n",
    "print('The graph in model:\\n{}'.format(model_def.graph))\n",
    "onnx.checker.check_model(model_def)\n",
    "print('The model is checked!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_def.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导出模型后，可以可视化\n",
    "onnx.save_model(model_def,'text.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = onnx.load_model('text.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型分为节点和初始化，注意他们是在图下面的\n",
    "#test_model.graph\n",
    "#test_model.graph.node\n",
    "test_model.graph.initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: create a model with two nodes, Y's shape is unknown\n",
    "node1 = helper.make_node('Transpose', ['X'], ['Y'], perm=[1, 0, 2])\n",
    "node2 = helper.make_node('Transpose', ['Y'], ['Z'], perm=[1, 0, 2])\n",
    "\n",
    "graph = helper.make_graph(\n",
    "    [node1, node2],\n",
    "    'two-transposes',\n",
    "    [helper.make_tensor_value_info('X', TensorProto.FLOAT, (2, 3, 4))],\n",
    "    [helper.make_tensor_value_info('Z', TensorProto.FLOAT, (2, 3, 4))],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torch.onnx\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "        类型声明，g是图，这是一个assert的装饰器\n",
    "        @parse_args('v', 'i', 'fs')\n",
    "        foo(g, a, b, c):\n",
    "          assert isinstance(a, torch._C.Value)\n",
    "          assert isinstance(b, int)\n",
    "          assert isinstance(c, list)\n",
    "          assert isinstance(c[0], float)\n",
    "      \n",
    "        \"v\":不需要转换, 保持 torch._C.Value.\n",
    "        \"i\": int\n",
    "        \"is\": list(int)\n",
    "        \"f\": float\n",
    "        \"fs\": list of float\n",
    "        \"b\": bool\n",
    "        \"s\": str\n",
    "        \"t\": torch.Tensor   \n",
    "      \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 如何导出ONNX的OP表示 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Aten库自带算子（张量可以直接使用的函数）\n",
    "    这种形式：虽然有直接使用的算子函数，但是在ONNX中没有正确对应的算子，需要进行符号函数声明\n",
    "    如 torch.asinh = Asinh，这样才能调用到对应算子\n",
    "    用 register_op 可以为 ATen 算子补充注册符号函数\n",
    "    如果在 g.op() 里不加前面的命名空间，则算子会被默认成 ONNX 的官方算子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#只要写一个符号函数，符号函数一般就是函数名字\n",
    "#其作用就是 1 关联函数映射  2 算子捏合 3 类型转化\n",
    "\n",
    "#@parse_args(\"v\", \"v\", \"v\", \"i\", \"i\", \"i\",\"i\",\"none\")声明数据类型\n",
    "def asinh_symbolic(g, input, *, out=None):\n",
    "    #对应ONNX的算子,在onnx中没有asinh,只有Asinh\n",
    "    return g.op(\"Asinh\", input_i=input)\n",
    "#绑定，\"torch.asinh\"-------\"Asinh\"\n",
    "register_op('asinh', asinh_symbolic, '', 9)\n",
    "#register_op(opname, op, domain, version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 在torch.onnx 库中用register_custom_op_symbolic 来注册一个op,有各式要求‘mmcv::max’，必须是这样的\n",
    "#### _registry用于保存所有的自定义OP\n",
    "####  {('mmcv','3.5'):{'max':max,'min':min,'test':test},('other','1.0'):{'func1':func1,'func2':func2}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用 register_custom_op_symbolic 可以为 TorchScript 算子补充注册符号函数,也就是自定义算子\n",
    "from torch.onnx.symbolic_registry import is_registered_op,get_registered_op\n",
    "from torch.onnx.utils import register_custom_op_symbolic\n",
    "# register_custom_op_symbolic(symbolic_name, symbolic_fn, opset_version) \n",
    "#这个函数调用register_op进行操作注册，只是要求symbolic_name必须是domain::funcname的格式，\n",
    "#做了简单的格式检查，和register_op是一样的\n",
    "#@parse_args(\"v\", \"v\", \"v\", \"v\", \"v\", \"i\", \"i\", \"i\", \"i\", \"i\", \"i\", \"i\", \"i\", \"none\")\n",
    "def newfunc(g,input,max_value):\n",
    "    #调用都是onnx里面支持的OP，实现包装组合执行函数，那要看到底怎么组合出这个自定义算子\n",
    "    return  g.op('Constant', input, max_value)\n",
    "#注册自定义算子,这是把myfunc::newfunc 注册到onnx11中去，使用g.Op（‘myfunc::newfunc'，input）这种形式\n",
    "register_custom_op_symbolic('myfunc::newfunc', newfunc,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Diagnostic Run torch.onnx.export version 2.0.1+cpu ==============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 1 WARNING 0 ERROR ========================\n",
      "1 WARNING were not printed due to the log level.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#当没有已经存在的OP可以表示的时候\n",
    "class CAWeightFunction(torch.autograd.Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def symbolic(g, t, f,iou_threshold=10):\n",
    "        #转化属性值为常量，因为有些内部自带的OP接受参数的数据类型是特定的，需要用这个进行转化\n",
    "        #也有些自定义的不用，直接用float(iou_threshold)就可以了\n",
    "        iou_threshold = g.op( 'Constant',value_t=torch.tensor([iou_threshold], dtype=torch.float))\n",
    "        \n",
    "        \n",
    "        #即使没有任何实现也可以导出onnx格式，但是执行onnxruntime则需要调用具体函数来实现,只会取::后面部分作为OP_NAME\n",
    "        #如果没有::，他会到domain ::中寻找OP，找不到就报错了\n",
    "        return  g.op(\"myfunc::newfunc\", t)\n",
    "    \n",
    "    #onnx并不需要实现这个，C++或者CUDA的延伸函数才是在这里使用的\n",
    "    @staticmethod\n",
    "    def forward(ctx, t, f,iou_threshold):\n",
    "        n, c, h, w = t.size()\n",
    "        weight = torch.zeros(n, h + w - 1, h, w).to(t.device)\n",
    "        ctx.save_for_backward(t, f)\n",
    "        #out   =  torch.ops.myfunc.func()\n",
    "        return weight\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, dw):\n",
    "        t, f = ctx.saved_tensors\n",
    "        dt = torch.zeros_like(t)\n",
    "        df = torch.zeros_like(f)\n",
    "        return dt, df\n",
    "test= CAWeightFunction.apply\n",
    "class Mymode(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Mymode,self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3,10,kernel_size=3)\n",
    "        self.b = nn.Parameter(torch.randn(5,5))\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self,input):\n",
    "        x = self.conv1(input)\n",
    "        x = test(input,self.b,1.0)\n",
    "        return x\n",
    "        \n",
    "model = Mymode()   \n",
    "model.eval()\n",
    "dummy_input = torch.randn(1,3,10,10)\n",
    "c = torch.randn(1)\n",
    "v = torch.tensor(5.0)\n",
    "torch.onnx.export(model,\n",
    "                 (dummy_input,),\n",
    "                 'test.onnx',\n",
    "                 export_params=True,\n",
    "                  opset_version=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#辅助函数，不用再写复杂的模块了\n",
    "class WrapFunction(nn.Module):\n",
    "\n",
    "    def __init__(self, wrapped_function):\n",
    "        super(WrapFunction, self).__init__()\n",
    "        self.wrapped_function = wrapped_function\n",
    "\n",
    "    def forward(self, *args, **kwargs):\n",
    "        return self.wrapped_function(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom(torch.autograd.Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def symbolic(g, inputs,value):\n",
    "        #关键点！！！！！！！！！！！！\n",
    "        #这里的名字是要和函数对应的，mmcv是空间，Custom是函数名\n",
    "        #所有的属性名字必须和cpp文件中的一样，并且，名字中要有类型表示，比如\n",
    "        #\"value_add\"被用于cpp文件中提取Info，并且他是一个int类型，所以这里要给 value_add_i=value_add\n",
    "        #\"spatial_scale\"被用于cpp文件，他的类型是float，所以这里要给 spatial_scale_f=spatial_scale\n",
    "        #\"mode\"被用于cpp文件，他是string，所以这里要用 mode_s=pool_mode\n",
    "        #\"aligned\"被用于cpp文件，他是bool，所以这里要用aligned_i=aligned\n",
    "        #总结，就是 name_type这种形式才能识别\n",
    "        return g.op('mmcv::Custom',inputs,value_add_f=value)\n",
    "    @staticmethod\n",
    "    def forward(ctx,inputs,value):\n",
    "        outputs =inputs +value\n",
    "        return outputs\n",
    "testfunc = custom.apply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    @parse_args('v', 'i', 'fs') 这个是对输入进行类型转换的装饰器\n",
    "    foo(g, a, b, c):\n",
    "    \"v\": 不转化, keep torch._C.Value.\n",
    "    \"i\": int\n",
    "    \"is\": list(int)\n",
    "    \"f\": float\n",
    "    \"fs\": list of float\n",
    "    \"b\": bool\n",
    "    \"s\": str\n",
    "    \"t\": torch.Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_value =1.0\n",
    "#other = value\n",
    "def func(inputs):\n",
    "    return testfunc(inputs,_value)#other=value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped_model = WrapFunction(func)\n",
    "wrapped_model.cpu().eval()\n",
    "#初始化模型输入\n",
    "inputs = torch.randn(1,3,3)\n",
    "#导出onnx模型，可以考虑其他参数的使用\n",
    "#导出onnx模型，可以考虑其他参数的使用\n",
    "with torch.no_grad():\n",
    "    torch.onnx.export(wrapped_model,\n",
    "                      (inputs,),\n",
    "                      'sample.onnx',\n",
    "                      input_names=['inputs'])\n",
    "#bug:RuntimeError: Unable to cast from non-held to held instance (T& to Holder<T>) (compile in debug mode for type information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = onnx.load('sample.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成onnxruntime的模型\n",
    "sess = rt.InferenceSession('sample.onnx', session_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成onnxruntime的模型\n",
    "sess = rt.InferenceSession('sample.onnx', session_options)\n",
    "#获取结果，输入要和input_names对应起来\n",
    "onnx_output = sess.run(None, {\n",
    "    'inputs': inputs.detach().numpy(),\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 算子学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_op(name,inputs,outputs,op,\n",
    "             filename='op.onnx'):\n",
    "    '''\n",
    "    1v1算子检查\n",
    "    '''\n",
    "    graph= make_graph([make_node(\n",
    "    name,\n",
    "    inputs=inputs,\n",
    "    outputs=outputs)],\n",
    "    'test',\n",
    "    [make_tensor_value_info(inputs[0], TensorProto.FLOAT, [3,3])],\n",
    "    [make_tensor_value_info(outputs[0], TensorProto.FLOAT, [3,3])])\n",
    "    model = make_model(graph)\n",
    "    onnx.save_model(model,filename)\n",
    "    sess = rt.InferenceSession(filename)\n",
    "    \n",
    "    inputs =torch.rand(3,3)-0.1\n",
    "    onnx_output = sess.run(None, {\n",
    "    'x': inputs.detach().numpy(),})\n",
    "    \n",
    "    return np.allclose(onnx_output,op(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
