{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch.onnx\n",
    "#!pip install onnxruntime\n",
    "import onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wget https://github.com/microsoft/onnxruntime/releases/download/v1.8.1/onnxruntime-linux-x64-1.8.1.tgz\n",
    "tar -zxvf onnxruntime-linux-x64-1.8.1.tgz\n",
    "cd onnxruntime-linux-x64-1.8.1\n",
    "os.environ['ONNXRUNTIME_DIR'] = '/kaggle/working/onnxruntime-linux-x64-1.8.1'\n",
    "export ONNXRUNTIME_DIR=$(pwd)\n",
    "export LD_LIBRARY_PATH=$ONNXRUNTIME_DIR/lib:$LD_LIBRARY_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#先将模型载入\n",
    "model = test_model()\n",
    "state = torch.load('test.pth')\n",
    "model.load_state_dict(state['model'], strict=True)\n",
    "\n",
    "#将模型设置成为eval（）模式\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input to the model\n",
    "#需要构造完整的输入形状\n",
    "batch_size=1\n",
    "x = torch.randn(batch_size, 3, 224, 224, requires_grad=True)\n",
    "\n",
    "#这里需要补全参数,因为多个输入难以指定\n",
    "\n",
    "from functools import partial \n",
    "temp_forward=model.forward\n",
    "model.forward=partial(model.forward,img_metas={}, return_loss=False)\n",
    "torch_out = model(x)\n",
    "\n",
    "#  torch.onnx.export(model, (x, {'y': None, 'z': z}), ‘test.onnx’)参数也可以用字典的形式传入，不要上面的方式\n",
    "# Export the model\n",
    "with torch.no_grad():\n",
    "    torch.onnx.export(model,               # model being run\n",
    "                  x,                         # model input (or a tuple for multiple inputs)\n",
    "                  \"test2.onnx\",   # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=10,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names = ['input'],   # 自定义input names\n",
    "                  output_names = ['output'], # 自定义output names\n",
    "                  dynamic_axes={'input' : {0 : 'batch_size', 2: 'width',3: 'height'},'output' : {0 : 'batch_size'}})\n",
    "    \n",
    "#所谓的动态dynamic_axes指的就是给定的输入维度，哪些是可能改变的，0,2,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#载入onnx格式的模型\n",
    "import onnx\n",
    "onnx_model=onnx.load('test.onnx')#直接将onnx的图载入\n",
    "\n",
    "#检查一下\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读入图片\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "pic_path='/kaggle/input/10-monkey-species/validation/validation/n8/n801.jpg'\n",
    "\n",
    "#变形\n",
    "img=Image.open(pic_path)\n",
    "resize = transforms.Resize([224, 224])\n",
    "img = resize(img)\n",
    "\n",
    "#转成张量 ，预处理也可以在这里做\n",
    "to_tensor = transforms.ToTensor()\n",
    "img_y = to_tensor(img)\n",
    "img_y.unsqueeze_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#执行推断\n",
    "#因为是在onnxruntime上执行的，所以是将.onnx文件直接作为图传入，形成session\n",
    "ort_session = onnxruntime.InferenceSession('test.onnx')\n",
    "\n",
    "#这个是将输入放到正确的设备上\n",
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "# compute ONNX Runtime output prediction执行的方法\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x)}#输入{'name':输入张量}\n",
    "ort_outs = ort_session.run(None, ort_inputs)#输出，其后要考虑对其进行后处理，生成最终的预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare ONNX Runtime and PyTorch results\n",
    "np.testing.assert_allclose(to_numpy(torch_out), ort_outs[0], rtol=1e-03, atol=1e-05)\n",
    "\n",
    "print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "img = Image.open(\"./_static/img/cat.jpg\")\n",
    "resize = transforms.Resize([224, 224])\n",
    "img = resize(img)\n",
    "\n",
    "img_ycbcr = img.convert('YCbCr')\n",
    "img_y, img_cb, img_cr = img_ycbcr.split()\n",
    "\n",
    "to_tensor = transforms.ToTensor()\n",
    "img_y = to_tensor(img_y)\n",
    "img_y.unsqueeze_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#以字典的形式，将模型的输入指定\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(img_y)}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "img_out_y = ort_outs[0]\n",
    "\n",
    "#这里生成的结果可进行后处理生成最后的预测结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcv.cnn import get_model_complexity_info\n",
    "model.eval()\n",
    "input_shape=(3,384,384)\n",
    "model.forward = model.forward_dummy\n",
    "flops, params = get_model_complexity_info(model, input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 修改ONNX模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#修改onnx模型的案例   解决模型转换冲突\n",
    "graph = onnx_model.graph  #图\n",
    "nodes = graph.node   #节点列表\n",
    "initializers = graph.initializer  #权重参数\n",
    "    \n",
    "for node in nodes:\n",
    "    #遍历找到指定node，修改内容\n",
    "    if node.name=='Conv_25':\n",
    "        node.attribute[1].ints=10\n",
    "        #节点的所有属性\n",
    "        node.input=[\"1\",\"2\"]\n",
    "        node.output=['3','4']\n",
    "        nodes.remove(node)\n",
    "        #构造新的节点\n",
    "        new_node = onnx.helper.make_node(\n",
    "                    'NonMaxSuppression',\n",
    "                        node_inputs[:2],\n",
    "                        node_outputs,\n",
    "                        score_threshold=score_threshold,\n",
    "                        offset=offset)                 \n",
    "        nodes.insert(idx, new_node)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试使用函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import onnx\n",
    "import onnxruntime as rt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from packaging import version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_file = 'tmp.onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrapFunction(nn.Module):\n",
    "\n",
    "    def __init__(self, wrapped_function):\n",
    "        super(WrapFunction, self).__init__()\n",
    "        self.wrapped_function = wrapped_function\n",
    "\n",
    "    def forward(self, *args, **kwargs):\n",
    "        return self.wrapped_function(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_grid_sample(func, input, grid, ort_custom_op_path=''):\n",
    "    wrapped_model = WrapFunction(func).eval()\n",
    "\n",
    "    input_names = ['input', 'grid']\n",
    "    output_names = ['output']\n",
    "\n",
    "    with torch.no_grad():\n",
    "        torch.onnx.export(\n",
    "            wrapped_model, (input, grid),\n",
    "            onnx_file,\n",
    "            export_params=True,\n",
    "            keep_initializers_as_inputs=True,\n",
    "            input_names=input_names,\n",
    "            output_names=output_names,\n",
    "            opset_version=11)\n",
    "\n",
    "    onnx_model = onnx.load(onnx_file)\n",
    "\n",
    "    session_options = rt.SessionOptions()\n",
    "    if ort_custom_op_path:\n",
    "        session_options.register_custom_ops_library(ort_custom_op_path)\n",
    "\n",
    "    # get onnx output\n",
    "    input_all = [node.name for node in onnx_model.graph.input]\n",
    "    input_initializer = [node.name for node in onnx_model.graph.initializer]\n",
    "    net_feed_input = list(set(input_all) - set(input_initializer))\n",
    "    assert (len(net_feed_input) == 2)\n",
    "    sess = rt.InferenceSession(onnx_file, session_options)\n",
    "    ort_result = sess.run(None, {\n",
    "        'input': input.detach().numpy(),\n",
    "        'grid': grid.detach().numpy()\n",
    "    })\n",
    "    pytorch_results = wrapped_model(input.clone(), grid.clone())\n",
    "    os.remove(onnx_file)\n",
    "    assert np.allclose(pytorch_results, ort_result, atol=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实时视频检测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import warnings\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import onnx\n",
    "import onnxruntime as rt\n",
    "import mmcv\n",
    "import torch\n",
    "from packaging import version\n",
    "from torch import nn\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch.onnx\n",
    "from helper import preprocess_example_input,bbox2result\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#载入onnx格式的模型\n",
    "output_file='yolox.onnx'\n",
    "onnx_model = onnx.load(output_file)#直接将onnx的图载入\n",
    "#检查一下\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(1,3,640,640)\n",
    "input_img='E:\\dog.jpg'\n",
    "normalize_cfg=dict(mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375])\n",
    "input_config = {\n",
    "    'input_shape': input_shape,\n",
    "    'input_path': input_img,\n",
    "    'normalize_cfg': normalize_cfg\n",
    "}\n",
    "one_img, one_meta = preprocess_example_input(input_config)\n",
    "tensor_data = [one_img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读入图片\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "pic_path='E:/dog.jpg'\n",
    "\n",
    "#变形\n",
    "img=Image.open(pic_path)\n",
    "resize = transforms.Resize([640, 640])\n",
    "img = resize(img)\n",
    "\n",
    "#转成张量 ，预处理也可以在这里做\n",
    "to_tensor = transforms.ToTensor()\n",
    "img_y = to_tensor(img)\n",
    "img_y.unsqueeze_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#这个是将输入放到正确的设备上\n",
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "# compute ONNX Runtime output prediction执行的方法\n",
    "#ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(img_y)}#输入{'name':输入张量}\n",
    "#ort_outs = ort_session.run(None, ort_inputs)#输出，其后要考虑对其进行后处理，生成最终的预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.array([123.675, 116.28, 103.53], dtype=np.float32)\n",
    "std = np.array([58.395, 57.12, 57.375], dtype=np.float32)\n",
    "colors = [(220, 20, 60), (119, 11, 32), (0, 0, 142), (0, 0, 230),\n",
    "               (106, 0, 228), (0, 60, 100), (0, 80, 100), (0, 0, 70),\n",
    "               (0, 0, 192), (250, 170, 30), (100, 170, 30), (220, 220, 0),\n",
    "               (175, 116, 175), (250, 0, 30), (165, 42, 42), (255, 77, 255),\n",
    "               (0, 226, 252), (182, 182, 255), (0, 82, 0), (120, 166, 157),\n",
    "               (110, 76, 0), (174, 57, 255), (199, 100, 0), (72, 0, 118),\n",
    "               (255, 179, 240), (0, 125, 92), (209, 0, 151), (188, 208, 182),\n",
    "               (0, 220, 176), (255, 99, 164), (92, 0, 73), (133, 129, 255),\n",
    "               (78, 180, 255), (0, 228, 0), (174, 255, 243), (45, 89, 255),\n",
    "               (134, 134, 103), (145, 148, 174), (255, 208, 186),\n",
    "               (197, 226, 255), (171, 134, 1), (109, 63, 54), (207, 138, 255),\n",
    "               (151, 0, 95), (9, 80, 61), (84, 105, 51), (74, 65, 105),\n",
    "               (166, 196, 102), (208, 195, 210), (255, 109, 65), (0, 143, 149),\n",
    "               (179, 0, 194), (209, 99, 106), (5, 121, 0), (227, 255, 205),\n",
    "               (147, 186, 208), (153, 69, 1), (3, 95, 161), (163, 255, 0),\n",
    "               (119, 0, 170), (0, 182, 199), (0, 165, 120), (183, 130, 88),\n",
    "               (95, 32, 0), (130, 114, 135), (110, 129, 133), (166, 74, 118),\n",
    "               (219, 142, 185), (79, 210, 114), (178, 90, 62), (65, 70, 15),\n",
    "               (127, 167, 115), (59, 105, 106), (142, 108, 45), (196, 172, 0),\n",
    "               (95, 54, 80), (128, 76, 255), (201, 57, 1), (246, 0, 122),\n",
    "               (191, 162, 208)]\n",
    "\n",
    "classes = ('person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "               'train', 'truck', 'boat', 'traffic light', 'fire hydrant',\n",
    "               'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog',\n",
    "               'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe',\n",
    "               'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
    "               'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat',\n",
    "               'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "               'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
    "               'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot',\n",
    "               'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
    "               'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop',\n",
    "               'mouse', 'remote', 'keyboard', 'cell phone', 'microwave',\n",
    "               'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock',\n",
    "               'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush')\n",
    "n = len(classes)\n",
    "thr_score = 0.3\n",
    "#执行推断\n",
    "#因为是在onnxruntime上执行的，所以是将.onnx文件直接作为图传入，形成session\n",
    "ort_session = rt.InferenceSession('yolo.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FPS, 30)\n",
    "while True:\n",
    "    ret,img = cap.read()\n",
    "    \n",
    "    print('one')\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    img = gray.astype(np.float32)\n",
    "    img = cv2.resize(img,(320,320))\n",
    "    #img = mmcv.imresize(img,(640,640),backend='cv2')\n",
    "    img = mmcv.imnormalize(img,mean,std)\n",
    "    \n",
    "    #转成张量 ，预处理也可以在这里做\n",
    "    to_tensor = transforms.ToTensor()\n",
    "    img_y = to_tensor(img) \n",
    "    img_y.unsqueeze_(0)\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: img_y.numpy()}#输入{'name':输入张量}\n",
    "    start_time = time.time()\n",
    "    ort_outs = ort_session.run(None, ort_inputs)#输出，其后要考虑对其进行后处理，生成最终的预测结果\n",
    "    ort_dets, ort_labels = ort_outs[:2]\n",
    "    stop_time = time.time()\n",
    "    onnx_results = bbox2result(ort_dets,ort_labels,n)\n",
    "    \n",
    "    \n",
    "    for i in range(n):\n",
    "        if len(onnx_results[i])!=0:\n",
    "            for x1,y1,x2,y2,score in onnx_results[i]:\n",
    "                if score>thr_score:\n",
    "                    # choose color for the label\n",
    "                    color = tuple(map(int, colors[i]))\n",
    "                    # draw box\n",
    "                    cv2.rectangle(img=img,\n",
    "                                  #一定是整数类型\n",
    "                                  pt1=(int(x1),int(y1)),\n",
    "                                  pt2=(int(x2),int(y2)),\n",
    "                                  color=color, \n",
    "                                  thickness=3)\n",
    "\n",
    "                    # draw label name inside the box\n",
    "                    cv2.putText(img=img,\n",
    "                                #\n",
    "                                text=f\"{classes[i]}{score:.2f}time:{stop_time-start_time}\",\n",
    "                                org=(int(x1) + 10, int(x2) + 5),\n",
    "                                fontFace=cv2.FONT_HERSHEY_COMPLEX, \n",
    "                                fontScale=gray.shape[1] / 1000, \n",
    "                                color=color,\n",
    "                                thickness=1, \n",
    "                                lineType=cv2.LINE_AA)\n",
    "                    cv2.imshow('img',img)\n",
    "\n",
    "    if cv2.waitKey(1) &0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
