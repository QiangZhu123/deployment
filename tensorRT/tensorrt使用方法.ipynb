{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PIP安装\n",
    "!python3 -m pip install --upgrade setuptools pip\n",
    "!python3 -m pip install nvidia-pyindex\n",
    "!pip install polygraphy\n",
    "!python3 -m pip install --upgrade nvidia-tensorrt\n",
    "\n",
    "!python3 -m pip install colored\n",
    "!pip install onnx-graphsurgeon\n",
    "!pip install onnxruntime\n",
    "#!pip cuda-python\n",
    "#!pip install pycuda --default-timeout=100 -i https://pypi.tuna.tsinghua.edu.cn/simple/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自定义网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入\n",
    "import tensorrt as trt\n",
    "#print(trt.__version__)\n",
    "assert trt.Builder(trt.Logger())\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 过程\n",
    "    1.创建Builder\n",
    "    2.创建Network\n",
    "    3.创建Parser\n",
    "    4.绑定输入、输出及自定义组件\n",
    "    5.序列化或者反序列化\n",
    " \n",
    "    6.传输计算数据\n",
    "    7.执行计算\n",
    "    8.传输计算结果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#记录器\n",
    "logger     = trt.Logger(trt.Logger.INFO)\n",
    "builder    = trt.Builder(logger)\n",
    "\n",
    "#三元素\n",
    "network    = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))#动态的shape模式\n",
    "config     = builder.create_builder_config()\n",
    "profile    = builder.create_optimization_profile()\n",
    "\n",
    "#设置参数\n",
    "config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 1 << 30)     # 设置空间给 TensoRT 尝试优化，单位 Byte\n",
    "#fp16模式\n",
    "#config.flags= 1<<int(trt.BuilderFlag.FP16)\n",
    "\n",
    "#对于特定层的精度设置\n",
    "#layer.precision = trt.float32\n",
    "#手写网络\n",
    "#设置输入，动态输入在这里设置\n",
    "inputTensor = network.add_input('inputT0', trt.float32, [-1, -1, -1]) \n",
    "\n",
    "#                                  最小形状    最优形状   最大形状\n",
    "profile.set_shape(inputTensor.name, [1, 1, 1], [3, 4, 5], [6, 8, 10]) \n",
    "config.add_optimization_profile(profile)\n",
    "\n",
    "#层，层的方法在下面\n",
    "identityLayer  = network.add_identity(inputTensor)\n",
    "\n",
    "#标记输出\n",
    "network.mark_output(identityLayer.get_output(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10.0.0版本的\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "#执行推断需要对数据进行传输\n",
    "#生成序列化\n",
    "#engine = builder.build_engine(network,config)\n",
    "engineString   =builder.build_serialized_network(network,config)\n",
    "engine        = trt.Runtime(logger).deserialize_cuda_engine(engineString)\n",
    "#创建执行的类似进程\n",
    "context        =engine.create_execution_context()\n",
    "stream         =cuda.Stream()\n",
    "\n",
    "#设置第一个输入的大小,动态输入才能设置\n",
    "#context.set_binding_shape(0,[3,4,5])\n",
    "context.set_input_shape('input',[1,3,224,224])\n",
    "#输入和输出的个数[input0,input1,output0,output1]\n",
    "nInput = np.sum([engine.binding_is_input(i) for i in range(engine.num_bindings)])  # 获取 engine 绑定信息\n",
    "nOutput = engine.num_bindings - nInput\n",
    "#具体数据，考虑使用torch的数据张量\n",
    "data = np.arange(3 * 4 * 5, dtype=np.float32).reshape(3, 4, 5)              # 准备数据和 Host/Device 端内存\n",
    "\n",
    "bufferH = []\n",
    "bufferH.append(np.ascontiguousarray(data.reshape(-1)))\n",
    "#填充主机上的输入、输出数据\n",
    "for i in range(nInput, nInput + nOutput):\n",
    "    s = engine.get_tensor_name(1)\n",
    "    bufferH.append(np.empty(context.get_tensor_shape(s), dtype=trt.nptype(engine.get_tensor_dtype(s))))\n",
    "bufferD = []\n",
    "for i in range(nInput + nOutput):\n",
    "    bufferD.append(cuda.mem_alloc(bufferH[i].nbytes))\n",
    "    #bufferD.append(cuda.cuMemAlloc(bufferH[i].nbytes)[1])\n",
    "for i in range(nInput):               # 首先将 Host 数据拷贝到 Device 端\n",
    "    cuda.memcpy_htod_async(bufferD[i], bufferH[i],stream)\n",
    "    #cuda.cuMemcpyHtoD(bufferD[i], bufferH[i].ctypes.data, bufferH[i].nbytes)\n",
    "    \n",
    "#context.execute_v2(bufferD)\n",
    "context.execute_async_v2([a.data_ptr(),b.data_ptr()],0)\n",
    "\n",
    "for i in range(nInput, nInput + nOutput):                                   # 将结果从 Device 端拷回 Host 端\n",
    "    cuda.memcpy_dtoh_async(bufferH[i], bufferD[i], stream)\n",
    "    #cuda.cuMemcpyDtoH(bufferH[i].ctypes.data, bufferD[i], bufferH[i].nbytes)\n",
    "stream.synchronize()\n",
    "\n",
    "'''\n",
    "for b in bufferD:              # 释放 Device 端内存\n",
    "    cuda.cuMemFree(b)\n",
    "'''\n",
    "outputs = [out.cpu().numpy() for out in bufferH]\n",
    "print('data:',data.shape,'\\n',data)\n",
    "print('outputH0',outputH0.shape,'\\n',outputH0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10.2以后版本的推断方法\n",
    "stream = cuda.Stream()\n",
    "a=torch.rand(32,3,224,224).cuda()\n",
    "b= torch.rand(32,1000).cuda()\n",
    "context.set_binding_shape(engine.get_binding_index(\"input\"), (1, 3, image_height, image_width))\n",
    "#engine.num_io_tensors\n",
    "context.set_tensor_address(engine.get_tensor_name(0), a.data_ptr())#输入\n",
    "context.set_tensor_address(engine.get_tensor_name(1), b.data_ptr())#输出\n",
    "context.execute_async_v3(stream.handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 细化网络处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建日志,用于查看信息，可以共享使用\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "#手动创建一个TENSORRT网络\n",
    "#builder 作为构建网络的入口\n",
    "#网络的参数统一使用builder_config保存\n",
    "\n",
    "#准备创建builder \n",
    "with trt.Builder(TRT_LOGGER) as builder, \n",
    "    #准备创建网络\n",
    "    builder.create_network() as network，\n",
    "    #网络的参数统一使用builder_config保存\n",
    "    builder.create_builder_config() as config:\n",
    "    #设置参数\n",
    "    config.max_workspace_size = 1 << 20 \n",
    "        \n",
    "    \n",
    "    #指定好输入，构建完engine后要使用这个\n",
    "    input_tensor = network.add_input(name=INPUT_NAME,#输入名称\n",
    "                                     dtype=trt.float32, #输入类型\n",
    "                                     shape=INPUT_SHAPE)#输入大小\n",
    "    \n",
    "    \n",
    "    # ---------------------------Add a convolution layer----------------------------\n",
    "    conv1_w = weights['conv1.weight'].numpy()#从权重中提取出参数\n",
    "    conv1_b = weights['conv1.bias'].numpy()\n",
    "    conv1 = network.add_convolution(input=input_tensor,#这是上一层的输出\n",
    "                                    num_output_maps=20,\n",
    "                                    kernel_shape=(5, 5),\n",
    "                                    kernel=conv1_w,\n",
    "                                    bias=conv1_b)#添加一个5*5卷积层\n",
    "    conv1.stride = (1, 1)\n",
    "    \n",
    "    #------------------------------------------------------------------------------\n",
    "    \n",
    "    pool1 = network.add_pooling(input=conv1.get_output(0), #用这个函数从上一层中获得输出\n",
    "                                type=trt.PoolingType.MAX,\n",
    "                                window_size=(2, 2))\n",
    "    #conv1.get_output(0)为上一层的输出\n",
    "    pool1.stride = (2, 2)\n",
    "    #-----------------------------------------------------------------------\n",
    "    \n",
    "    conv2_w = weights['conv2.weight'].numpy()\n",
    "    conv2_b = weights['conv2.bias'].numpy()\n",
    "    conv2 = network.add_convolution(pool1.get_output(0),\n",
    "                                    50, (5, 5),\n",
    "                                    conv2_w, \n",
    "                                    conv2_b)\n",
    "    conv2.stride = (1, 1)\n",
    "    #-----------------------------------------------------------------------------\n",
    "    \n",
    "    pool2 = network.add_pooling(conv2.get_output(0), trt.PoolingType.MAX, (2, 2))\n",
    "    pool2.stride = (2, 2)\n",
    "    \n",
    "    #-----------------------------------------------------------------------------\n",
    "    fc1_w = weights['fc1.weight'].numpy()\n",
    "    fc1_b = weights['fc1.bias'].numpy()\n",
    "    fc1 = network.add_fully_connected(input=pool2.get_output(0),\n",
    "                                      num_outputs=500,\n",
    "                                      kernel=fc1_w,\n",
    "                                        bias=fc1_b)\n",
    "    #-----------------------------------------------------------------------------\n",
    "    relu1 = network.add_activation(fc1.get_output(0), \n",
    "                                   trt.ActivationType.RELU)\n",
    "    #-----------------------------------------------------------------------------\n",
    "    \n",
    "    fc2_w = weights['fc2.weight'].numpy()\n",
    "    fc2_b = weights['fc2.bias'].numpy()\n",
    "    fc2 = network.add_fully_connected(relu1.get_output(0), \n",
    "                                      OUTPUT_SIZE, fc2_w, fc2_b)\n",
    "    fc2.get_output(0).name =OUTPUT_NAME\n",
    "    #-----------------------------------------------------------------------------\n",
    "    #指定好网络的输出，也是后面要使用到的\n",
    "    network.mark_output(fc2.get_output(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打印逐层信息（注意是上面网络逐层信息而不是 serialozedNetwork 的逐层信息）\n",
    "for i in range(network.num_layers):\n",
    "    layer = network.get_layer(i)\n",
    "    print(i, \"%s,in=%d,out=%d,%s\" % (str(layer.type)[10:], layer.num_inputs, layer.num_outputs, layer.name))\n",
    "    for j in range(layer.num_inputs):\n",
    "        tensor = layer.get_input(j)\n",
    "        if tensor == None:\n",
    "            print(\"\\tInput  %2d:\" % j, \"None\")\n",
    "        else:\n",
    "            print(\"\\tInput  %2d:%s,%s,%s\" % (j, tensor.shape, str(tensor.dtype)[9:], tensor.name))\n",
    "    for j in range(layer.num_outputs):\n",
    "        tensor = layer.get_output(j)\n",
    "        if tensor == None:\n",
    "            print(\"\\tOutput %2d:\" % j, \"None\")\n",
    "        else:\n",
    "            print(\"\\tOutput %2d:%s,%s,%s\" % (j, tensor.shape, str(tensor.dtype)[9:], tensor.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 动态输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))\n",
    "profile = builder.create_optimization_profile()\n",
    "config.max_workspace_size = 1 << 30\n",
    "inputTensor = network.add_input('inputT0', trt.float32, [-1, -1, -1])  # 指定输入张量\n",
    "#                                  最小， 最常见， 最大\n",
    "profile.set_shape(inputTensor.name, [1, 1, 1], [3, 4, 5], [6, 8, 10])   # 指定输入张量 Dynamic Shape 范围\n",
    "config.add_optimization_profile(profile)\n",
    "\n",
    "context.set_binding_shape(0, [3, 4, 5])  # Dynamic Shape 模式需要绑定真实数据形状\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 快速解析onnx格式模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = trt.OnnxParser(network, logger)  #先创建一个解析器\n",
    "with open(onnxFile, 'rb') as model: # 再解析onnx格式模型\n",
    "    parser.parse(model.read())\n",
    "#再保存称为engine文件\n",
    "config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 1 << 20) \n",
    "serialized_engine = builder.build_serialized_network(network, config)\n",
    "with open('sample.engine', 'wb') as f:\n",
    "    #也可以是.plan格式文件\n",
    "    f.write(serialized_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputTensor = network.get_input(0)\n",
    "profile.set_shape(inputTensor.name, (1, 1, 28, 28), (4, 1, 28, 28), (16, 1, 28, 28))\n",
    "config.add_optimization_profile(profile)\n",
    "\n",
    "network.unmark_output(network.get_output(0))  # 去掉输出张量 'y'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 可以保存的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tmp.plan','rb') as f:\n",
    "    file.write(engineString)\n",
    "#反序列化\n",
    "engine = trt.Runtime(logger).deserialize_cuda_engine(file)     # 使用 Runtime 来创建 engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自定义网络层\n",
    "    这个只是使用Python进行模块添加的工作，函数还是要C++实现，需要先编译好op的动态库so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctypes\n",
    "TRT_LOGGER = trt.Logger()\n",
    "soFile = \"./AddScalarPlugin.so\"\n",
    "#这一行很重要，当解码模型时候要用到\n",
    "trt.init_libnvinfer_plugins(TRT_LOGGER, '')\n",
    "ctypes.cdll.LoadLibrary(soFile)\n",
    "#ctypes.CDLL(osp.join(dir_path, 'libamirstan_plugin.so'))\n",
    "\n",
    "PLUGIN_CREATORS = trt.get_plugin_registry().plugin_creator_list\n",
    "\n",
    "#获得注册的操作，并且创建，和上面的方法是一样的\n",
    "def get_trt_plugin(plugin_name):\n",
    "    PLUGIN_CREATORS = trt.get_plugin_registry().plugin_creator_list\n",
    "    plugin = None\n",
    "    for plugin_creator in PLUGIN_CREATORS:\n",
    "        if plugin_creator.name == plugin_name:\n",
    "\n",
    "            lrelu_slope_field = trt.PluginField(\"neg_slope\", np.array([0.1], dtype=np.float32), trt.PluginFieldType.FLOAT32)\n",
    "            #列表形式保存属性\n",
    "            field_collection = trt.PluginFieldCollection([lrelu_slope_field])\n",
    "\n",
    "            plugin = plugin_creator.create_plugin(name=plugin_name, field_collection=field_collection)\n",
    "    return plugin\n",
    "    \n",
    "#构建新的层,查看creater中如何定义plugin的名字\n",
    "lrelu = network.add_plugin_v2(inputs=[input_layer], plugin=get_trt_plugin(\"LReLU_TRT\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 量化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.set_flag(trt.BuilderFlag.INT8)\n",
    "inputs=torch.rand(1,2,2,2).cuda()\n",
    "int8_calib_batch_size=2\n",
    "int8_calib_dataset = TensorBatchDataset(inputs)\n",
    "calibrator = DatasetCalibrator(\n",
    "    int8_calib_dataset, \n",
    "    algorithm=trt.CalibrationAlgoType.ENTROPY_CALIBRATION_2\n",
    ")\n",
    "\n",
    "config.int8_calibrator = calibrator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 可视化所有信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspector = engine.create_engine_inspector()\n",
    "inspector.execution_context = context\n",
    "print(inspector.get_layer_information(0, LayerInformationFormat.JSON)\n",
    "print(inspector.get_engine_information(LayerInformationFormat.JSON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 量化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_IMAGES_PER_BATCH = 5\n",
    "batchstream = ImageBatchStream(NUM_IMAGES_PER_BATCH, calibration_files)\n",
    "Int8_calibrator = EntropyCalibrator([\"input_node_name\"], batchstream)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.set_flag(trt.BuilderFlag.INT8)\n",
    "config.int8_calibrator = Int8_calibrator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# polygraphy\n",
    "     转化模型，并且评估\n",
    "     !pip install colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run模式\n",
    "#fold节点，topk\n",
    "!polygraphy surgeon sanitize /kaggle/input/testonnx/tmp.onnx \\\n",
    "    --fold-constants \\\n",
    "    -o /kaggle/working/folded.onnx\n",
    "\n",
    "#运行,评估onnxruntime和tensorrt分别的执行效率，并且保存引擎文件\n",
    "!polygraphy run /kaggle/working/folded.onnx \\\n",
    "    #选用多种后端\n",
    "    --trt  --onnxrt \\\n",
    "    #输入的名字和形状\n",
    "    --input-shapes input:[1,3,1333,800] \\\n",
    "    --save-engine temp.plane\n",
    "    #标记所有层，对比输出，可能有些层合并后不能用了\n",
    "    --onnx-outputs mark all \\\n",
    "    --trt-outputs mark all \n",
    "'''\n",
    "[I]         PASSED | Difference is within tolerance (rel=1e-05, abs=1e-05)\n",
    "[I]     PASSED | All outputs matched | Outputs: ['labels', 'dets']\n",
    "[I] PASSED | Command: /opt/conda/bin/polygraphy run /kaggle/working/folded.onnx --trt --onnxrt --input-shapes input:[1,3,1333,800] --save-engine temp.plan\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect模式 可以显示所有层\n",
    "#可查看的文件包括.onnx,  .plan,  .engine,  .pb,  .json\n",
    "!polygraphy inspect model folded.onnx \\\n",
    "    --mode=basic --display-as=trt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#surgeon 模式 可以修改图：分割图，折叠图，\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 错误处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RuntimeError: CUDA error: an illegal memory access was encountered CUDA kernel errors might be \n",
    "asynchronously  reported at some other API call, so the stacktrace below might be incorrect.\n",
    "For debugging consider passing CUDA_LAUNCH_BLOCKING=1. Compile with `TORCH_USE_CUDA_DSA` to enable \n",
    "device-side assertions.\n",
    "\n",
    "检查数据，要放到cuda上才对"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvprof 被nsys替换了\n",
    "也是在cuda/bin下面\n",
    "\n",
    "nsys profile XXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最新格式使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnx_helper import ONNXClassifierWrapper\n",
    "N_CLASSES = 1000 # Our ResNet-50 is trained on a 1000 class ImageNet task\n",
    "trt_model = ONNXClassifierWrapper(\"resnet_engine.trt\", [BATCH_SIZE, N_CLASSES],\n",
    " target_dtype = PRECISION)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=32\n",
    "dummy_input_batch = np.zeros((BATCH_SIZE, 224, 224, 3), dtype = PRECISION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trt_model.predict(dummy_input_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
