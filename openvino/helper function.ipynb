{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c26a482",
   "metadata": {},
   "outputs": [],
   "source": [
    "INFER_NUMBER = 1000\n",
    "\n",
    "\n",
    "def benchmark_model(model: Any, input_data: np.ndarray, benchmark_name: str, device_name: str = \"CPU\") -> float:\n",
    "    \"\"\"\n",
    "    Helper function for benchmarking the model. It measures the time and prints results.\n",
    "    \"\"\"\n",
    "    # measure the first inference separately -  it may be slower as it contains also initialization\n",
    "    start = time.perf_counter()\n",
    "    model(input_data)\n",
    "    end = time.perf_counter()\n",
    "    first_infer_time = end - start\n",
    "    print(f\"{benchmark_name} on {device_name}. First inference time: {first_infer_time :.4f} seconds\")\n",
    "\n",
    "    # benchmarking\n",
    "    start = time.perf_counter()\n",
    "    for _ in range(INFER_NUMBER):\n",
    "        model(input_data)\n",
    "    end = time.perf_counter()\n",
    "\n",
    "    # elapsed time\n",
    "    infer_time = end - start\n",
    "\n",
    "    # print second per image and FPS\n",
    "    mean_infer_time = infer_time / INFER_NUMBER\n",
    "    mean_fps = INFER_NUMBER / infer_time\n",
    "    print(f\"{benchmark_name} on {device_name}: {mean_infer_time :.4f} seconds per image ({mean_fps :.2f} FPS)\")\n",
    "\n",
    "    return mean_infer_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2909b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(detections: np.ndarray) -> List[Tuple]:\n",
    "    \"\"\"\n",
    "    Postprocess the raw results from the model.\n",
    "    \"\"\"\n",
    "    # candidates - probability > 0.25\n",
    "    detections = detections[detections[..., 4] > 0.25]\n",
    "\n",
    "    boxes = []\n",
    "    labels = []\n",
    "    scores = []\n",
    "    for obj in detections:\n",
    "        xmin, ymin, ww, hh = obj[:4]\n",
    "        score = obj[4]\n",
    "        label = np.argmax(obj[5:])\n",
    "        # Create a box with pixels coordinates from the box with normalized coordinates [0,1].\n",
    "        boxes.append(\n",
    "            tuple(map(int, (xmin - ww // 2, ymin - hh // 2, ww, hh)))\n",
    "        )\n",
    "        labels.append(int(label))\n",
    "        scores.append(float(score))\n",
    "\n",
    "    # Apply non-maximum suppression to get rid of many overlapping entities.\n",
    "    # See https://paperswithcode.com/method/non-maximum-suppression\n",
    "    # This algorithm returns indices of objects to keep.\n",
    "    indices = cv2.dnn.NMSBoxes(\n",
    "        bboxes=boxes, scores=scores, score_threshold=0.25, nms_threshold=0.5\n",
    "    )\n",
    "\n",
    "    # If there are no boxes.\n",
    "    if len(indices) == 0:\n",
    "        return []\n",
    "\n",
    "    # Filter detected objects.\n",
    "    return [(labels[idx], scores[idx], boxes[idx]) for idx in indices.flatten()]\n",
    "\n",
    "\n",
    "def draw_boxes(img: np.ndarray, boxes):\n",
    "    \"\"\"\n",
    "    Draw detected boxes on the image.\n",
    "    \"\"\"\n",
    "    for label, score, box in boxes:\n",
    "        # Choose color for the label.\n",
    "        color = tuple(map(int, colors[label]))\n",
    "        # Draw a box.\n",
    "        x2 = box[0] + box[2]\n",
    "        y2 = box[1] + box[3]\n",
    "        cv2.rectangle(img=img, pt1=box[:2], pt2=(x2, y2), color=color, thickness=2)\n",
    "\n",
    "        # Draw a label name inside the box.\n",
    "        cv2.putText(\n",
    "            img=img,\n",
    "            text=f\"{classes[label]} {score:.2f}\",\n",
    "            org=(box[0] + 10, box[1] + 20),\n",
    "            fontFace=cv2.FONT_HERSHEY_COMPLEX,\n",
    "            fontScale=img.shape[1] / 1200,\n",
    "            color=color,\n",
    "            thickness=1,\n",
    "            lineType=cv2.LINE_AA,\n",
    "        )\n",
    "\n",
    "\n",
    "def show_result(results: np.ndarray):\n",
    "    \"\"\"\n",
    "    Postprocess the raw results, draw boxes and show the image.\n",
    "    \"\"\"\n",
    "    output_img = image.copy()\n",
    "\n",
    "    detections = postprocess(results)\n",
    "    draw_boxes(output_img, detections)\n",
    "\n",
    "    utils.show_array(output_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb812fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each detection, the description is in the [x_min, y_min, x_max, y_max, conf] format:\n",
    "# The image passed here is in BGR format with changed width and height. To display it in colors expected by matplotlib, use cvtColor function\n",
    "def convert_result_to_image(bgr_image, resized_image, boxes, threshold=0.3, conf_labels=True):\n",
    "    # Define colors for boxes and descriptions.\n",
    "    colors = {\"red\": (255, 0, 0), \"green\": (0, 255, 0)}\n",
    "\n",
    "    # Fetch the image shapes to calculate a ratio.\n",
    "    (real_y, real_x), (resized_y, resized_x) = bgr_image.shape[:2], resized_image.shape[:2]\n",
    "    ratio_x, ratio_y = real_x / resized_x, real_y / resized_y\n",
    "\n",
    "    # Convert the base image from BGR to RGB format.\n",
    "    rgb_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Iterate through non-zero boxes.\n",
    "    for box in boxes:\n",
    "        # Pick a confidence factor from the last place in an array.\n",
    "        conf = box[-1]\n",
    "        if conf > threshold:\n",
    "            # Convert float to int and multiply corner position of each box by x and y ratio.\n",
    "            # If the bounding box is found at the top of the image,\n",
    "            # position the upper box bar little lower to make it visible on the image.\n",
    "            (x_min, y_min, x_max, y_max) = [\n",
    "                int(max(corner_position * ratio_y, 10)) if idx % 2\n",
    "                else int(corner_position * ratio_x)\n",
    "                for idx, corner_position in enumerate(box[:-1])\n",
    "            ]\n",
    "\n",
    "            # Draw a box based on the position, parameters in rectangle function are: image, start_point, end_point, color, thickness.\n",
    "            rgb_image = cv2.rectangle(rgb_image, (x_min, y_min), (x_max, y_max), colors[\"green\"], 3)\n",
    "\n",
    "            # Add text to the image based on position and confidence.\n",
    "            # Parameters in text function are: image, text, bottom-left_corner_textfield, font, font_scale, color, thickness, line_type.\n",
    "            if conf_labels:\n",
    "                rgb_image = cv2.putText(\n",
    "                    rgb_image,\n",
    "                    f\"{conf:.2f}\",\n",
    "                    (x_min, y_min - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.8,\n",
    "                    colors[\"red\"],\n",
    "                    1,\n",
    "                    cv2.LINE_AA,\n",
    "                )\n",
    "\n",
    "    return rgb_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353ce548",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nncf\n",
    "#pip install -q \"nncf>=2.5.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819fa75d",
   "metadata": {},
   "source": [
    "# Semantic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238d9f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dim = 1\n",
    "boolean_cat_mask = (normalized_mask.argmax(class_dim) == sem_class_to_idx['cat'])\n",
    "from torchvision.utils import draw_segmentation_masks\n",
    "\n",
    "show(draw_segmentation_masks(image, masks=boolean_cat_mask, alpha=0.7, colors='yellow'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ed9838",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342320ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
