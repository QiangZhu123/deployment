{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab15e20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import nncf\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "# Instantiate your uncompressed model\n",
    "onnx_model = onnx.load_model(\"mobile.onnx\")\n",
    "\n",
    "# Provide validation part of the dataset to collect statistics needed for the compression algorithm\n",
    "val_dataset = datasets.ImageFolder(\"/kaggle/input/nclass-dataset\", transform=transforms.Compose([\n",
    "    transforms.Resize((224,224))\n",
    "    ,transforms.ToTensor()]))\n",
    "dataset_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1)\n",
    "\n",
    "# Step 1: Initialize transformation function\n",
    "input_name = onnx_model.graph.input[0].name\n",
    "def transform_fn(data_item):\n",
    "    images, _ = data_item\n",
    "    return {input_name: images.numpy()}\n",
    "\n",
    "# Step 2: Initialize NNCF Dataset\n",
    "calibration_dataset = nncf.Dataset(dataset_loader, transform_fn)\n",
    "# Step 3: Run the quantization pipeline\n",
    "#nncfg可以直接量化onnx模型，也可以量化ov模型，取决于你传入模型的执行后端\n",
    "quantized_model = nncf.quantize(onnx_model, calibration_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef112b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ... # openvino.runtime.Model object\n",
    "BATCHSIZE   = 32\n",
    "INPUT_SHAPE = [BATCHSIZE, 3, 224, 224]\n",
    "DEVICE      = 'cuda'\n",
    "PLATFORM    = TargetPlatform.TRT_INT8\n",
    "\n",
    "def load_calibration_dataset() -> Iterable:\n",
    "    # ------------------------------------------------------------\n",
    "    # 让我们从创建 calibration 数据开始做起， PPQ 需要你送入 32 ~ 1024 个样本数据作为校准数据集\n",
    "    # 它们应该尽可能服从真实样本的分布，量化过程如同训练过程一样存在可能的过拟合问题\n",
    "    # 你应当保证校准数据是经过正确预处理的、有代表性的数据，否则量化将会失败；校准数据不需要标签；数据集不能乱序\n",
    "    # ------------------------------------------------------------\n",
    "    return [torch.rand(size=INPUT_SHAPE) for _ in range(32)]\n",
    "\n",
    "\n",
    "quantized_model = nncf.quantize(model, calibration_dataset)\n",
    "\n",
    "\n",
    "#\n",
    "#names = ['layer_1', 'layer_2', 'layer_3']\n",
    "#types = ['Conv2d', 'Linear']\n",
    "#nncf.quantize(model, dataset, ignored_scope=nncf.IgnoredScope(names=names,types=types)\n",
    "#             target_device=nncf.TargetDevice.CPU\n",
    "#\n",
    "#              ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1463a5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openvino.runtime as ov\n",
    "from openvino.tools.mo import convert_model\n",
    "\n",
    "input_fp32 = ... # FP32 model input\n",
    "\n",
    "# export PyTorch model to ONNX model\n",
    "onnx_model_path = \"model.onnx\"\n",
    "torch.onnx.export(quantized_model, input_fp32, onnx_model_path)\n",
    "\n",
    "# convert ONNX model to OpenVINO model\n",
    "ov_quantized_model = convert_model(onnx_model_path)\n",
    "\n",
    "# compile the model to transform quantized operations to int8\n",
    "model_int8 = ov.compile_model(ov_quantized_model)\n",
    "\n",
    "res = model_int8(input_fp32)\n",
    "\n",
    "# save the model\n",
    "ov.serialize(ov_quantized_model, \"quantized_model.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cd24e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ba8b14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68eb3244",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
