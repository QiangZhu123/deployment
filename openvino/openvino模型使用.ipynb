{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88dd6440",
   "metadata": {},
   "source": [
    "# 完整脚本\n",
    "       \n",
    "       就三步，read,compile,forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "760a2dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openvino.runtime import Core\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import openvino as ov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f728c32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve(\n",
    "    url='https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/utils/notebook_utils.py',\n",
    "    filename='notebook_utils.py'\n",
    ")\n",
    "\n",
    "from notebook_utils import download_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b805fa18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcc674c02c524a7f84b898334b302f42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model\\classification.xml:   0%|          | 0.00/179k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "634fb64ce03a41cd99c455af069bce3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model\\classification.bin:   0%|          | 0.00/4.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('D:/myjupyter/深度学习/deployment/openvino/open1/model/classification.bin')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#看你选择什么模型\n",
    "ir_model_url = 'https://storage.openvinotoolkit.org/repositories/openvino_notebooks/models/002-example-models/'\n",
    "ir_model_name_xml = 'classification.xml'\n",
    "ir_model_name_bin = 'classification.bin'\n",
    "\n",
    "download_file(ir_model_url + ir_model_name_xml, filename=ir_model_name_xml, directory='model')\n",
    "download_file(ir_model_url + ir_model_name_bin, filename=ir_model_name_bin, directory='model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40db6cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ie = Core()\n",
    "devices = 'CPU'\n",
    "model_xml = 'model/classification.xml'\n",
    "#model_bin = 'resnet18.bin'\n",
    "#根本不需要使用.xml文件，不论是onnx，tensorflow,还是paddlepaddle，都可以直接读取，不用再MO处理\n",
    "net = ie.read_model(model= model_xml,\n",
    "                    #weights = model_bin\n",
    "                     )\n",
    "\n",
    "#如果是pytorch模型，需要转化以下\n",
    "#example_input = torch.zeros((1, 3, 224, 224))\n",
    "#net= ov.convert_model(pt_model, example_input=example_input)\n",
    "\n",
    "compiled_model = ie.compile_model(model=net,device_name=\"CPU\")\n",
    "#compiled_model = core.compile_model(model, device, {\"PERFORMANCE_HINT\": \"LATENCY\"})\n",
    "#compiled_model = core.compile_model(model, device, {\"PERFORMANCE_HINT\": \"THROUGHPUT\"})\n",
    "#输入输出层，每个层有名字和形状，查询后数据填充把\n",
    "input_layer =compiled_model.inputs[0]\n",
    "out_layer =compiled_model.outputs[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e844ec35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存导出，转换格式\n",
    "ov.save_model(model_onnx, output_model=\"model/exported_onnx_model.xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c760ef7",
   "metadata": {},
   "source": [
    "# 准备输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bef98f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "image_filename = \"data/coco_hollywood.jpg\"\n",
    "image_filename = download_file(\n",
    "    \"https://storage.openvinotoolkit.org/repositories/openvino_notebooks/data/data/image/coco_hollywood.jpg\",\n",
    "    directory=\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06221b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"data/coco_hollywood.jpg\")\n",
    "N, C, H, W = input_layer.shape\n",
    "resized_image = cv2.resize(src=image, dsize=(W, H))\n",
    "resized_image.shape\n",
    "#normalized_image = normalize(resized_image)\n",
    "input_data = np.expand_dims(np.transpose(resized_image, (2, 0, 1)), 0).astype(np.float32)\n",
    "input_data.shape\n",
    "#这些信息一般会和模型放在一起，去模型文件夹中可以找到。同时也有输出结果的信息，解释每一个维度\n",
    "#image = np.float32(image)/255.0\n",
    "#image[:,:,]-= (np.float32(0.485),np.float32(0.456),np.float32(0.406))\n",
    "#image = image.transpose(2,0,1)\n",
    "result = compiled_model([input_data])[out_layer]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8a7e60",
   "metadata": {},
   "source": [
    "# 特殊形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acbd919",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openvino.runtime import Core, PartialShape\n",
    "\n",
    "ie = Core()\n",
    "segmentation_model_xml = \"model/segmentation.xml\"\n",
    "segmentation_model = ie.read_model(model=segmentation_model_xml)\n",
    "segmentation_input_layer = segmentation_model.inputs[0]\n",
    "segmentation_output_layer = segmentation_model.outputs[0]\n",
    "\n",
    "new_shape = PartialShape([1, 3, 544, 544])#新的网络大小，batch大小也可以修改\n",
    "\n",
    "#这里返回None\n",
    "segmentation_model.reshape({segmentation_input_layer.any_name: new_shape})\n",
    "segmentation_compiled_model = ie.compile_model(model=segmentation_model, device_name=\"CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0025d9",
   "metadata": {},
   "source": [
    "# 视频异步对象检测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402dafec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import notebook_utils as utils\n",
    "def draw_boxes(frame, boxes):\n",
    "    for label, score, box in boxes:\n",
    "        # choose color for the label\n",
    "        color = tuple(map(int, colors[label]))\n",
    "        # draw box\n",
    "        cv2.rectangle(img=frame, pt1=box[:2], pt2=box[2:], color=color, thickness=3)\n",
    "        # draw label name inside the box\n",
    "        cv2.putText(img=frame, \n",
    "                    text=f\"{classes[label]} {score:.2f}\", \n",
    "                    org=(box[0] + 10, box[1] + 30),\n",
    "                    fontFace=cv2.FONT_HERSHEY_COMPLEX, \n",
    "                    fontScale=frame.shape[1] / 1000, \n",
    "                    color=color,\n",
    "                    thickness=1, \n",
    "                    lineType=cv2.LINE_AA)\n",
    "\n",
    "    return frame\n",
    "\n",
    "\n",
    "# main processing function to run object detection\n",
    "def run_object_detection(source=0, flip=False, use_popup=False, skip_first_frames=0):\n",
    "    player = None\n",
    "    try:\n",
    "        # create video player to play with target fps\n",
    "        player = utils.VideoPlayer(source=source, flip=flip, fps=30, skip_first_frames=skip_first_frames)\n",
    "        # start capturing\n",
    "        player.start()\n",
    "        if use_popup:\n",
    "            title = \"Press ESC to Exit\"\n",
    "            cv2.namedWindow(winname=title, flags=cv2.WINDOW_GUI_NORMAL | cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "        processing_times = collections.deque()\n",
    "        request = compiled_model.create_infer_request()\n",
    "        while True:\n",
    "            # grab the frame\n",
    "            frame = player.next()\n",
    "            if frame is None:\n",
    "                print(\"Source ended\")\n",
    "                break\n",
    "            # if frame larger than full HD, reduce size to improve the performance\n",
    "            scale = 1280 / max(frame.shape)\n",
    "            if scale < 1:\n",
    "                frame = cv2.resize(src=frame, dsize=None, fx=scale, fy=scale,\n",
    "                                   interpolation=cv2.INTER_AREA)\n",
    "\n",
    "            # resize image and change dims to fit neural network input\n",
    "            input_img = cv2.resize(src=frame, dsize=(width, height), interpolation=cv2.INTER_AREA)\n",
    "            # create batch of images (size = 1)\n",
    "            input_img = input_img[np.newaxis, ...]\n",
    "\n",
    "            # measure processing time\n",
    "\n",
    "            start_time = time.time()\n",
    "            # get results\n",
    "            request.infer(inputs={input_layer.any_name: input_img})\n",
    "            results = request.get_output_tensor(output_layer.index).data\n",
    "            stop_time = time.time()\n",
    "            # get poses from network results\n",
    "            #解码输出\n",
    "            boxes = process_results(frame=frame, results=results)\n",
    "\n",
    "            # draw boxes on a frame显示结果函数\n",
    "            frame = draw_boxes(frame=frame, boxes=boxes)\n",
    "\n",
    "            processing_times.append(stop_time - start_time)\n",
    "            # use processing times from last 200 frames\n",
    "            if len(processing_times) > 200:\n",
    "                processing_times.popleft()\n",
    "\n",
    "            _, f_width = frame.shape[:2]\n",
    "            # mean processing time [ms]\n",
    "            processing_time = np.mean(processing_times) * 1000\n",
    "            fps = 1000 / processing_time\n",
    "            cv2.putText(img=frame, text=f\"Inference time: {processing_time:.1f}ms ({fps:.1f} FPS)\", org=(20, 40),\n",
    "                        fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=f_width / 1000,\n",
    "                        color=(0, 0, 255), thickness=1, lineType=cv2.LINE_AA)\n",
    "\n",
    "            # use this workaround if there is flickering\n",
    "            if use_popup:\n",
    "                cv2.imshow(winname=title, mat=frame)\n",
    "                key = cv2.waitKey(1)\n",
    "                # escape = 27\n",
    "                if key == 27:\n",
    "                    break\n",
    "            else:\n",
    "                # encode numpy array to jpg\n",
    "                _, encoded_img = cv2.imencode(ext=\".jpg\", img=frame,\n",
    "                                              params=[cv2.IMWRITE_JPEG_QUALITY, 100])\n",
    "                # create IPython image\n",
    "                i = display.Image(data=encoded_img)\n",
    "                # display the image in this notebook\n",
    "                display.clear_output(wait=True)\n",
    "                display.display(i)\n",
    "    # ctrl-c\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupted\")\n",
    "    # any different error\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        if player is not None:\n",
    "            # stop capturing\n",
    "            player.stop()\n",
    "        if use_popup:\n",
    "            cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abf1639",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_object_detection(source=0, flip=True, use_popup=False)\n",
    "\n",
    "#video_file = \"../201-vision-monodepth/data/Coco Walking in Berkeley.mp4\"\n",
    "#run_object_detection(source=video_file, flip=False, use_popup=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe222ce4",
   "metadata": {},
   "source": [
    "# latency mode + shared memory\n",
    "  可以提升计算性能,真的会变快\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa84f3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#模式设置\n",
    "\n",
    "ov_auto_model = ie.compile_model(net, device_name=\"AUTO\", \n",
    "                        config={\"PERFORMANCE_HINT\": \"LATENCY\"})\n",
    "#将图片进行连续化处理\n",
    "c_input_image = np.ascontiguousarray(input_data, dtype=np.float32)\n",
    "#不用拷贝空间\n",
    "input_tensor = ov.Tensor(c_input_image, shared_memory=True)\n",
    "\n",
    "#result = ov_auto_model(input_tensor)[ov_auto_model.output(0)][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700fb2ac",
   "metadata": {},
   "source": [
    "# 评估模型速度用到的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f60a21b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "INFER_NUMBER = 10\n",
    "\n",
    "import time\n",
    "def benchmark_model(model, \n",
    "                    input_data: np.ndarray,\n",
    "                    benchmark_name: str,\n",
    "                    device_name: str = \"CPU\") -> float:\n",
    "    # measure the first inference separately -  it may be slower as it contains also initialization\n",
    "    start = time.perf_counter()\n",
    "    model(input_data)\n",
    "    end = time.perf_counter()\n",
    "    first_infer_time = end - start\n",
    "    print(f\"{benchmark_name} on {device_name}. First inference time: {first_infer_time :.4f} seconds\")\n",
    "\n",
    "    # benchmarking\n",
    "    start = time.perf_counter()\n",
    "    for _ in range(INFER_NUMBER):\n",
    "        model(input_data)\n",
    "    end = time.perf_counter()\n",
    "\n",
    "    # elapsed time\n",
    "    infer_time = end - start\n",
    "\n",
    "    # print second per image and FPS\n",
    "    mean_infer_time = infer_time / INFER_NUMBER\n",
    "    mean_fps = INFER_NUMBER / infer_time\n",
    "    print(f\"{benchmark_name} on {device_name}: {mean_infer_time :.4f} seconds per image ({mean_fps :.2f} FPS)\")\n",
    "\n",
    "    return mean_infer_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44d32dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name on CPU. First inference time: 0.3412 seconds\n",
      "name on CPU: 0.3432 seconds per image (2.91 FPS)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.34319900260015856"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_model(compiled_model,input_data,'name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ef3288b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ov_model on CPU. First inference time: 0.4687 seconds\n",
      "ov_model on CPU: 0.3058 seconds per image (3.27 FPS)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3058163809997495"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_model(ov_auto_model,input_data,'ov_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730313e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
