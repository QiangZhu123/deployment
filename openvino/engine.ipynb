{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d2bc166",
   "metadata": {},
   "source": [
    "# C++ 文件实现算子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c6a319",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <openvino/op/op.hpp>\n",
    "class MyCustomOp : public ov::op::Op {\n",
    "public:\n",
    "    OPENVINO_OP(\"MyCustomOp\", \"custom_opset\");\n",
    "    MyCustomOp() = default;\n",
    "    MyCustomOp(const ov::Output<ov::Node>& x);\n",
    "    void validate_and_infer_types() override;\n",
    "    std::shared_ptr<ov::Node> clone_with_new_inputs(const ov::OutputVector& new_args) const override;\n",
    "    bool visit_attributes(ov::AttributeVisitor& visitor) override;\n",
    "    bool evaluate(ov::TensorVector& outputs, const ov::TensorVector& inputs) const override;\n",
    "    bool has_evaluate() const override;\n",
    "private:\n",
    "    size_t m_input_shape_size = 0;\n",
    "};\n",
    "\n",
    "MyCustomOp::MyCustomOp(const ov::Output<ov::Node>& x) {\n",
    "    constructor_validate_and_infer_types();\n",
    "    set_input(0, x);\n",
    "}\n",
    "\n",
    "void MyCustomOp::validate_and_infer_types() {\n",
    "    auto input_shape = get_input_partial_shape(0);\n",
    "    auto input_rank = input_shape.rank().get_length();\n",
    "    set_output_type(0, get_input_element_type(0), get_input_partial_shape(0));\n",
    "}\n",
    "\n",
    "std::shared_ptr<ov::Node> MyCustomOp::clone_with_new_inputs(const ov::OutputVector& new_args) const {\n",
    "    return std::make_shared<MyCustomOp>(new_args.at(0));\n",
    "}\n",
    "\n",
    "bool MyCustomOp::visit_attributes(ov::AttributeVisitor& visitor) {\n",
    "    return true;\n",
    "}\n",
    "\n",
    "bool MyCustomOp::evaluate(ov::TensorVector& outputs, const ov::TensorVector& inputs) const {\n",
    "    auto x = inputs[0];\n",
    "    auto output_shape = x.get_partial_shape();\n",
    "    auto output_rank = output_shape.rank().get_length();\n",
    "    auto element_type = x.get_element_type();\n",
    "    auto& backend = *ov::runtime::Backend::get();\n",
    "\n",
    "    // 只支持 float 和 double 类型的输入\n",
    "    if (element_type != ov::element::f32 && element_type != ov::element::f64) {\n",
    "        throw ov::Exception(\"MyCustomOp only accepts float and double inputs.\");\n",
    "    }\n",
    "\n",
    "    if (element_type == ov::element::f32) {\n",
    "        auto output_tensor = ov::runtime::Tensor(ov::element::f32, output_shape);\n",
    "        auto sin_x = backend.sin(ov::runtime::TensorView<float>{x});\n",
    "        auto output_tensor_view = ov::runtime::TensorView<float>{output_tensor};\n",
    "        auto output_ptr = output_tensor_view.data();\n",
    "        auto sin_x_ptr = sin_x.data();\n",
    "        auto size = output_shape[0].get_length();\n",
    "        for (size_t i = 0; i < size; ++i) {\n",
    "            *output_ptr++ = 2 * sin_x_ptr[i] + 1;\n",
    "        }\n",
    "        outputs.push_back(output_tensor);\n",
    "    } else {\n",
    "        auto output_tensor = ov::runtime::Tensor(ov::element::f64, output_shape);\n",
    "        auto sin_x = backend.sin(ov::runtime::TensorView<double>{x});\n",
    "        auto output_tensor_view = ov::runtime::TensorView<double>{output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35af0d9",
   "metadata": {},
   "source": [
    "# 复杂自定义：以max_pool为例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f46a6db",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_13288/1107137848.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [6]\u001b[1;36m\u001b[0m\n\u001b[1;33m    // Copyright (C) 2018-2022 Intel Corporation\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#pragma once\n",
    "#include <limits>\n",
    "#include \"openvino/op/util/max_pool_base.hpp\"\n",
    "\n",
    "namespace ov {\n",
    "namespace op {\n",
    "namespace v8 {\n",
    "\n",
    "class OPENVINO_API MaxPool : public op::util::MaxPoolBase {\n",
    "public:\n",
    "    //宏\n",
    "    OPENVINO_OP(\"MaxPool\", \"opset8\", op::util::MaxPoolBase);\n",
    "    BWDCMP_RTTI_DECLARATION;\n",
    "    MaxPool() = default;\n",
    "\n",
    "    /// 构造函数\n",
    "    ///\n",
    "    /// \\param arg \n",
    "    /// \\param strides \n",
    "    /// \\param dilations \n",
    "    /// \\param pads_begin \n",
    "    /// \\param pads_end \n",
    "    /// \\param kernel \n",
    "    /// \\param rounding_type \n",
    "    /// \\param auto_pad \n",
    "    /// \\param index_element_type \n",
    "    /// \\param axis \n",
    "    ///Strides 和Shape都是列表\n",
    "    MaxPool(const Output<Node>& arg,\n",
    "            const Strides& strides,\n",
    "            const Strides& dilations,\n",
    "            const Shape& pads_begin,\n",
    "            const Shape& pads_end,\n",
    "            const Shape& kernel,\n",
    "            const op::RoundingType rounding_type = op::RoundingType::FLOOR,\n",
    "            const PadType auto_pad = op::PadType::EXPLICIT,\n",
    "            const element::Type index_element_type = element::i64,\n",
    "            const int64_t axis = 0);\n",
    "\n",
    "    bool visit_attributes(AttributeVisitor& visitor) override;\n",
    "    void validate_and_infer_types() override;\n",
    "\n",
    "    std::shared_ptr<Node> clone_with_new_inputs(const OutputVector& new_args) const override;\n",
    "\n",
    "    // 属性获取函数\n",
    "    const Strides& get_dilations() const noexcept {\n",
    "        return m_dilations;\n",
    "    }\n",
    "    //属性修改函数\n",
    "    void set_dilations(const Strides& dilations) {\n",
    "        m_dilations = dilations;\n",
    "    }\n",
    "\n",
    "    // 属性获取函数\n",
    "    element::Type get_index_element_type() const noexcept {\n",
    "        return m_index_element_type;\n",
    "    }\n",
    "    //属性修改函数\n",
    "    void set_index_element_type(const element::Type index_element_type) {\n",
    "        m_index_element_type = index_element_type;\n",
    "    }\n",
    "\n",
    "    // 属性获取函数\n",
    "    int64_t get_axis() const {\n",
    "        return m_axis;\n",
    "    }\n",
    "    //属性修改函数\n",
    "    void set_axis(const int64_t axis) {\n",
    "        m_axis = axis;\n",
    "    }\n",
    "\n",
    "    bool has_evaluate() const override;\n",
    "    OPENVINO_SUPPRESS_DEPRECATED_START\n",
    "    bool evaluate(const HostTensorVector&, const HostTensorVector&) const override;\n",
    "    OPENVINO_SUPPRESS_DEPRECATED_END\n",
    "\n",
    "private:\n",
    "    Strides m_dilations;\n",
    "    element::Type m_index_element_type{element::i64};\n",
    "    int64_t m_axis{0};\n",
    "};\n",
    "}  // namespace v8\n",
    "}  // namespace op\n",
    "}  // namespace ov\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f0c0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include \"ngraph/op/max_pool.hpp\"\n",
    "#include \"itt.hpp\"\n",
    "#include \"ngraph/attribute_visitor.hpp\"\n",
    "#include \"ngraph/op/add.hpp\"\n",
    "#include \"ngraph/op/constant.hpp\"\n",
    "#include \"ngraph/runtime/host_tensor.hpp\"\n",
    "#include \"ngraph/runtime/reference/max_pool.hpp\"\n",
    "#include \"ngraph/validation_util.hpp\"\n",
    "\n",
    "using namespace std;\n",
    "using namespace ngraph;\n",
    "\n",
    "bool op::v1::MaxPool::update_auto_padding(const PartialShape& in_shape,\n",
    "                                          Shape& new_pads_end,\n",
    "                                          Shape& new_pads_begin) const\n",
    "{\n",
    "    bool update_auto_padding_succeed = true;\n",
    "    if (m_auto_pad == PadType::SAME_UPPER || m_auto_pad == PadType::SAME_LOWER)\n",
    "    {\n",
    "        CoordinateDiff pads_end, pads_begin;\n",
    "        update_auto_padding_succeed =\n",
    "            try_apply_auto_padding(in_shape,\n",
    "                                   m_kernel,\n",
    "                                   m_strides,\n",
    "                                   Strides(m_kernel.size(), 1), // No dilation\n",
    "                                   m_auto_pad,\n",
    "                                   pads_end,\n",
    "                                   pads_begin);\n",
    "        new_pads_end = Shape(pads_end.begin(), pads_end.end());\n",
    "        new_pads_begin = Shape(pads_begin.begin(), pads_begin.end());\n",
    "    }\n",
    "    return update_auto_padding_succeed;\n",
    "}\n",
    "\n",
    "NGRAPH_RTTI_DEFINITION(op::v1::MaxPool, \"MaxPool\", 1);\n",
    "//带参构造\n",
    "op::v1::MaxPool::MaxPool(const Output<Node>& arg,\n",
    "                         const Strides& strides,\n",
    "                         const Shape& pads_begin,\n",
    "                         const Shape& pads_end,\n",
    "                         const Shape& kernel,\n",
    "                         op::RoundingType rounding_type,\n",
    "                         const PadType& auto_pad)\n",
    "    : Op({arg})\n",
    "    , m_kernel(kernel)\n",
    "    , m_strides(strides)\n",
    "    , m_pads_begin(pads_begin)\n",
    "    , m_pads_end(pads_end)\n",
    "    , m_auto_pad(auto_pad)\n",
    "    , m_rounding_type(rounding_type)\n",
    "{\n",
    "    //固定，调用的是validate_and_infer_types\n",
    "    constructor_validate_and_infer_types();\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b56b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "//访问所有的属性，对所有的属性都要使用\n",
    "bool ngraph::op::v1::MaxPool::visit_attributes(AttributeVisitor& visitor)\n",
    "{   //作用域名，格式就是他的函数名\n",
    "    NGRAPH_OP_SCOPE(v1_MaxPool_visit_attributes);\n",
    "    visitor.on_attribute(\"strides\", m_strides);\n",
    "    visitor.on_attribute(\"pads_begin\", m_pads_begin);\n",
    "    visitor.on_attribute(\"pads_end\", m_pads_end);\n",
    "    visitor.on_attribute(\"kernel\", m_kernel);\n",
    "    visitor.on_attribute(\"rounding_type\", m_rounding_type);\n",
    "    visitor.on_attribute(\"auto_pad\", m_auto_pad);\n",
    "    return true;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c8ca9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "void op::v1::MaxPool::validate_and_infer_types()\n",
    "{\n",
    "    NGRAPH_OP_SCOPE(v1_MaxPool_validate_and_infer_types);\n",
    "    if (0 == m_strides.size())\n",
    "    {\n",
    "        m_strides = Strides(m_kernel.size(), 1);\n",
    "    }\n",
    "\n",
    "    if (0 == m_pads_begin.size())\n",
    "    {\n",
    "        m_pads_begin = Shape(m_kernel.size(), 0);\n",
    "    }\n",
    "\n",
    "    if (0 == m_pads_end.size())\n",
    "    {\n",
    "        m_pads_end = Shape(m_kernel.size(), 0);\n",
    "    }\n",
    "\n",
    "    const PartialShape& arg_shape = get_input_partial_shape(0);\n",
    "\n",
    "    NODE_VALIDATION_CHECK(this,\n",
    "                          arg_shape.rank().compatible(3) || arg_shape.rank().compatible(4) ||\n",
    "                              arg_shape.rank().compatible(5),\n",
    "                          \"Expected a 3D, 4D or 5D tensor for the input. Got: \",\n",
    "                          arg_shape);\n",
    "\n",
    "    if (arg_shape.rank().is_static())\n",
    "    {\n",
    "        NODE_VALIDATION_CHECK(this,\n",
    "                              static_cast<int64_t>(m_pads_end.size()) ==\n",
    "                                  arg_shape.rank().get_max_length() - 2,\n",
    "                              \"Expected pads_end size to be equal to input size - 2. Got: \",\n",
    "                              m_pads_end.size());\n",
    "\n",
    "        NODE_VALIDATION_CHECK(this,\n",
    "                              static_cast<int64_t>(m_pads_begin.size()) ==\n",
    "                                  arg_shape.rank().get_max_length() - 2,\n",
    "                              \"Expected pads_begin size to be equal to input size - 2. Got: \",\n",
    "                              m_pads_begin.size());\n",
    "        NODE_VALIDATION_CHECK(this,\n",
    "                              static_cast<int64_t>(m_kernel.size()) ==\n",
    "                                  arg_shape.rank().get_max_length() - 2,\n",
    "                              \"Expected kernel size to be equal to input size - 2. Got: \",\n",
    "                              m_kernel.size());\n",
    "        NODE_VALIDATION_CHECK(this,\n",
    "                              static_cast<int64_t>(m_pads_end.size()) ==\n",
    "                                  arg_shape.rank().get_max_length() - 2,\n",
    "                              \"Expected strides size to be equal to input size - 2. Got: \",\n",
    "                              m_strides.size());\n",
    "    }\n",
    "\n",
    "    auto output_shape = PartialShape::dynamic();\n",
    "    if (arg_shape.rank().is_static())\n",
    "    {\n",
    "        output_shape =\n",
    "            std::vector<Dimension>(arg_shape.rank().get_max_length(), Dimension::dynamic());\n",
    "        if (arg_shape[0].is_static())\n",
    "        {\n",
    "            output_shape[0] = arg_shape[0]; // batch size\n",
    "        }\n",
    "        if (arg_shape[1].is_static())\n",
    "        {\n",
    "            output_shape[1] = arg_shape[1]; // channel size\n",
    "        }\n",
    "    }\n",
    "\n",
    "    bool update_auto_padding_succeed = true;\n",
    "    if (m_auto_pad == PadType::SAME_UPPER || m_auto_pad == PadType::SAME_LOWER)\n",
    "    {\n",
    "        update_auto_padding_succeed = update_auto_padding(arg_shape, m_pads_end, m_pads_begin);\n",
    "    }\n",
    "    if (m_auto_pad == PadType::VALID)\n",
    "    {\n",
    "        m_pads_end = Shape(m_pads_end.size(), 0);\n",
    "        m_pads_begin = Shape(m_pads_begin.size(), 0);\n",
    "    }\n",
    "    // infer_batched_forward_pooling wants CoordinateDiffs for these, while the pooling ops for\n",
    "    // now still take Shape (no negative padding).\n",
    "    CoordinateDiff pads_begin(m_pads_begin.begin(), m_pads_begin.end());\n",
    "    CoordinateDiff pads_end(m_pads_end.begin(), m_pads_end.end());\n",
    "\n",
    "    set_output_type(0,\n",
    "                    get_input_element_type(0),\n",
    "                    update_auto_padding_succeed\n",
    "                        ? infer_batched_pooling_forward(this,\n",
    "                                                        arg_shape,\n",
    "                                                        pads_begin,\n",
    "                                                        pads_end,\n",
    "                                                        m_kernel,\n",
    "                                                        m_strides,\n",
    "                                                        true,\n",
    "                                                        m_rounding_type == op::RoundingType::CEIL)\n",
    "                        : output_shape);\n",
    "}\n",
    "\n",
    "\n",
    "shared_ptr<Node> op::v1::MaxPool::get_default_value() const\n",
    "{\n",
    "    return op::Constant::create(get_element_type(), get_shape(), {0});\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15ab638",
   "metadata": {},
   "outputs": [],
   "source": [
    "//创建一个新的OP，把参数传递给他即可\n",
    "shared_ptr<Node> op::v1::MaxPool::clone_with_new_inputs(const OutputVector& new_args) const\n",
    "{  //作用域\n",
    "    NGRAPH_OP_SCOPE(v1_MaxPool_clone_with_new_inputs);\n",
    "    check_new_args_count(this, new_args);\n",
    "    //把参数传递进去\n",
    "    return make_shared<v1::MaxPool>(\n",
    "        new_args.at(0), m_strides, m_pads_begin, m_pads_end, m_kernel, m_rounding_type, m_auto_pad);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e80daac2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_13288/4027719477.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [7]\u001b[1;36m\u001b[0m\n\u001b[1;33m    using namespace std;\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "//自定义的OP，都是以这种形式来实现\n",
    "namespace maxpool\n",
    "{\n",
    "    template <element::Type_t ET>\n",
    "    inline bool evaluate(const HostTensorPtr& arg,\n",
    "                         const HostTensorPtr& out,\n",
    "                         const Shape& out_shape,\n",
    "                         const Shape& window_shape,\n",
    "                         const Strides& window_movement_strides,\n",
    "                         const Shape& padding_below,\n",
    "                         const Shape& padding_above)\n",
    "    {\n",
    "        using T = typename element_type_traits<ET>::value_type;\n",
    "        out->set_shape(out_shape);\n",
    "        //这个是已经有的实现函数\n",
    "        runtime::reference::max_pool<T>(arg->get_data_ptr<ET>(),\n",
    "                                        out->get_data_ptr<ET>(),\n",
    "                                        arg->get_shape(),\n",
    "                                        out_shape,\n",
    "                                        window_shape,\n",
    "                                        window_movement_strides,\n",
    "                                        padding_below,\n",
    "                                        padding_above);\n",
    "        return true;\n",
    "    }\n",
    "\n",
    "    bool evaluate_maxpool(const HostTensorPtr& arg,\n",
    "                          const HostTensorPtr& out,\n",
    "                          const Shape& out_shape,\n",
    "                          const Shape& kernel,\n",
    "                          const Strides& strides,\n",
    "                          const Shape& pad_begin,\n",
    "                          const Shape& pad_end)\n",
    "    {\n",
    "        bool rc = true;\n",
    "        auto arg_shape = arg->get_shape();\n",
    "        //根据输出的类型来选择调用的函数\n",
    "        switch (out->get_element_type())\n",
    "        {// NGRAPH_TYPE_CASE就是调用evaluate函数的意思，\n",
    "            NGRAPH_TYPE_CASE(evaluate_maxpool,i32,arg,out,out_shape,kernel,strides,pad_begin,pad_end);\n",
    "            NGRAPH_TYPE_CASE(evaluate_maxpool,i64,arg,out,out_shape,kernel,strides,pad_begin,pad_end);\n",
    "            NGRAPH_TYPE_CASE(evaluate_maxpool, u32, arg, out, out_shape, kernel, strides, pad_begin, pad_end);\n",
    "            NGRAPH_TYPE_CASE(evaluate_maxpool, u64, arg, out, out_shape, kernel, strides, pad_begin, pad_end);\n",
    "            NGRAPH_TYPE_CASE(evaluate_maxpool, f16, arg, out, out_shape, kernel, strides, pad_begin, pad_end);\n",
    "            NGRAPH_TYPE_CASE(evaluate_maxpool, f32, arg, out, out_shape, kernel, strides, pad_begin, pad_end);\n",
    "        default: rc = false; break;\n",
    "        }\n",
    "        return rc;\n",
    "    }\n",
    "} // namespace maxpool\n",
    "\n",
    "bool op::v1::MaxPool::evaluate_maxpool(const HostTensorVector& outputs,\n",
    "                                       const HostTensorVector& inputs) const\n",
    "{\n",
    "    auto arg_shape = inputs[0]->get_partial_shape();\n",
    "    \n",
    "    //必须实现获得属性的函数\n",
    "    auto pads_begin_s = get_pads_begin();\n",
    "    auto pads_end_s = get_pads_end();\n",
    "    \n",
    "    update_auto_padding(arg_shape, pads_begin_s, pads_end_s);\n",
    "    CoordinateDiff pads_begin(pads_begin_s.begin(), pads_begin_s.end());\n",
    "    CoordinateDiff pads_end(pads_end_s.begin(), pads_end_s.end());\n",
    "    auto out_shape = infer_batched_pooling_forward(this,\n",
    "                                                   arg_shape,\n",
    "                                                   pads_begin,\n",
    "                                                   pads_end,\n",
    "                                                   get_kernel(),\n",
    "                                                   get_strides(),\n",
    "                                                   true,\n",
    "                                                   get_rounding_type() == op::RoundingType::CEIL);\n",
    "    //获得属性的函数就是在这里调用的\n",
    "    return maxpool::evaluate_maxpool(inputs[0],\n",
    "                                     outputs[0],\n",
    "                                     out_shape.get_shape(),\n",
    "                                     get_kernel(),\n",
    "                                     get_strides(),\n",
    "                                     get_pads_begin(),\n",
    "                                     get_pads_end());\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bd1218",
   "metadata": {},
   "outputs": [],
   "source": [
    "//输入的都是常列表引用\n",
    "bool op::v1::MaxPool::evaluate(const HostTensorVector& outputs,\n",
    "                               const HostTensorVector& inputs) const\n",
    "{\n",
    "    //版本_FUNC_has_evaluate  = v0_Log_has_evaluate，保证和has_evaluate里的一样\n",
    "    NGRAPH_OP_SCOPE(v1_MaxPool_evaluate);\n",
    "    //要写自定义的OP执行函数，在这里调用\n",
    "    return evaluate_maxpool(outputs, inputs);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15e0e607",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_13288/3756834844.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [8]\u001b[1;36m\u001b[0m\n\u001b[1;33m    //当输入是指定数据类型时可以执行，是固定的形式,这是和evaluate配套出现的函数\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "//当输入是指定数据类型时可以执行，是固定的形式,这是和evaluate配套出现的函数\n",
    "//只要修改作用域标识符即可 ： 版本_FUNC_has_evaluate  = v0_Log_has_evaluate\n",
    "//按照输入的类型确定是否可以执行evaluate\n",
    "bool op::v1::MaxPool::has_evaluate() const\n",
    "{\n",
    "    //标识符\n",
    "    NGRAPH_OP_SCOPE(v0_Log_has_evaluate)\n",
    "    \n",
    "    switch (get_input_element_type(0))\n",
    "    {\n",
    "    //哪些类型可以执行evaluate\n",
    "    case ngraph::element::i32:\n",
    "    case ngraph::element::i64:\n",
    "    case ngraph::element::u32:\n",
    "    case ngraph::element::u64:\n",
    "    case ngraph::element::f16:\n",
    "    case ngraph::element::f32: return true;\n",
    "    default: break;\n",
    "    }\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c3f95c",
   "metadata": {},
   "source": [
    "# python 生成MO 的识别Extensions\n",
    "    OP只是一个属性保存的，使用OP给Node提供属性而已\n",
    "共三步\n",
    "1. 将OP加入到Model Optimizer中以便于生成IR文件\n",
    "2. 在NGraph中执行op，可以云寻\n",
    "3. 在IE中让不同的设备都可以执行\n",
    "第一步\n",
    "\n",
    "    分成三类\n",
    "1.Model Optimizer operation.基类构建\n",
    "2.A framework operation extractor.特征提取器\n",
    "3.front, middle or back 阶段的变形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea5e087",
   "metadata": {},
   "outputs": [],
   "source": [
    "命令 mo -->>subprocess_main-->>main_onnx.py-->>main-->>_convert-->>driver----\n",
    "                    get_onnx_cli_parser解析参数--|\n",
    "\n",
    "\n",
    "------>>prepare_ir----->>unified_pipeline \n",
    "                            建立一个图，对图进行四个操作[load,front,mid,back]\n",
    "                            get_replacers_order：先对四个操作进行排序\n",
    "                                _registered_classes_dict全局字典中保存所有类，对他们进行图排序\n",
    "                    \n",
    "    \n",
    "                            apply_replacements_list：遍历图的所有节点，每个类都要\n",
    "                                    进行对应的find_and_replace_pattern\n",
    "            \n",
    "                                    force_clean_up---->>clean_up\n",
    "                \n",
    "                                    shape_inference(graph)-->>infer\n",
    "\n",
    "    \n",
    "----->>emit_ir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510b5519",
   "metadata": {},
   "source": [
    "### mo_extension/ops/cosh.py\n",
    "\n",
    "_registered_classes_dict全局字典中保存了所有的ops,front,middle,back类\n",
    "有Op, Activation, Elementwise, UnaryElementwise, LogicalElementwise,EmbeddingBagBase, ReduceOp, Scatter, ScatterNDBase, FFTBase这些父类，需要取找所有子类放入到字典中，导入所有文件\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0647ec30",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mo'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfront\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpartial_infer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01melemental\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m copy_shape_infer\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Graph, Node\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mop\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Op\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mo'"
     ]
    }
   ],
   "source": [
    "from mo.front.common.partial_infer.elemental import copy_shape_infer\n",
    "from mo.graph.graph import Graph, Node\n",
    "from mo.ops.op import Op\n",
    "from mo.ops.pooling import Pooling\n",
    "import numpy as np\n",
    "from extensions.ops.argmax import arg_ops_infer\n",
    "\n",
    "\n",
    "class ArgMinOp(Op):\n",
    "    version = 'opset1'\n",
    "    op = 'ArgMin'\n",
    "    enabled = False                          #表示该OP是否会被MO使用或者包括\n",
    "    operation = None                         #简单的实现OP方法,写了这个可以不再用C++编写具体实现\n",
    "    #operation = staticmethod(lambda x: 1 / (1 + np.exp(-x)))   可以直接写出计算OP\n",
    "    def __init__(self, graph: Graph, attrs: dict):\n",
    "        mandatory_props = {\n",
    "            'type':self.op,\n",
    "            'op': self.op,\n",
    "            'infer': self.infer,   \n",
    "            'operation': self.operation,      \n",
    "            'type_infer': self.type_infer,            #节点的结构属性\n",
    "            'output_type': np.int64,\n",
    "            'in_ports_count': 2,\n",
    "            'out_ports_count': 1,\n",
    "        }#这些都是默认的,给的是两个attrs字典\n",
    "        super().__init__(graph, mandatory_props, attrs)\n",
    "    \n",
    "    def supported_attrs(self):\n",
    "        return [\n",
    "            'top_k',\n",
    "            'axis',\n",
    "        ]#这个方法返回列表，其存储的是需要保存到IR中attrs，从上面的初始化中来\n",
    "    \n",
    "    @staticmethod\n",
    "    def infer(node):                      #  计算输出的形状\n",
    "        \"\"\"\n",
    "        静态方法或者类方法，传入的是自身OP构造的Node\n",
    "        该方法是用来计算输出的形状，类型等张量信息，需要用到node自身的port中所保存data\n",
    "        node.inport(2).data.get_shape\n",
    "        或者node.in_node(2).shape\n",
    "        而data本身包含的六个方法对应处理其属性,\n",
    "        get_shape()\n",
    "        set_shape()\n",
    "        get_value()\n",
    "        set_value()\n",
    "        get_attr()\n",
    "        set_attr()\n",
    "        value,shape,type\n",
    "    \n",
    "        最终的结果就是用这六个方法来计算的得到\n",
    "        \n",
    "        通过设置输出port中data的形状完成set_shape，形状是np数组set_value\n",
    "        \n",
    "        在这里也可以计算\n",
    "        shape = x\n",
    "        value =c\n",
    "        node.out_port(1).data.set_shape(shape)\n",
    "        node.out_port(1).data.set_value(value)\n",
    "        \n",
    "        或者用这种更简单的方法\n",
    "        node.out_node(0).shape = shape\n",
    "        node.out_node(0).value = value\n",
    "        \"\"\"\n",
    "    @staticmethod\n",
    "    def type_infer(node):\n",
    "        \"\"\"\n",
    "        类型推断set_data_type\n",
    "        \"\"\"\n",
    "    def backend_attrs(self): #这个是用于保存到IR中的属性，并不是全有\n",
    "        return [\n",
    "            ('strides', lambda node: ','.join(map(str, node['stride'][node.spatial_dims]))),\n",
    "            ('kernel', lambda node: ','.join(map(str, node['window'][node.spatial_dims]))),\n",
    "            ('pads_begin', lambda node: ','.join(map(str, get_backend_pad(node.pad, node.spatial_dims, 0))))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe3bd2e",
   "metadata": {},
   "source": [
    "# 2 Operation Extractor\n",
    "### mo_extension/front/onnx/cosh_ext.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f46c439",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'extensions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#这步操作是先于OP的，载入框架模型后就要进行属性提取，用于后续构造图节点\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mextensions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01margmin\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArgMinOp    \u001b[38;5;66;03m#要把OP类导入进来，进行属性添加\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfront\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextractor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FrontExtractorOp\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfront\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextractors\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m onnx_attr\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'extensions'"
     ]
    }
   ],
   "source": [
    "#这步操作是先于OP的，载入框架模型后就要进行属性提取，用于后续构造图节点\n",
    "#基类是mo.front.extractor.FrontExtractorOp，用内置类方法extract来获得唯一参数NOde的属性\n",
    "from extensions.ops.argmin import ArgMinOp    #要把OP类导入进来，进行属性添加\n",
    "from mo.front.extractor import FrontExtractorOp\n",
    "from mo.front.onnx.extractors.utils import onnx_attr\n",
    "\n",
    "#FrontExtractorOp作为基类，\n",
    "#里面只是定义了\n",
    "#    registered_ops = {}\n",
    "#    registered_cls = []\n",
    "#子类必须实现类方法extract\n",
    "#\n",
    "class ArgMinFrontExtractor(FrontExtractorOp):\n",
    "    op = 'ArgMin'                    #OP名字\n",
    "    enabled = True                  #MO是否会用到\n",
    "\n",
    "    @classmethod\n",
    "    def extract(cls, node):\n",
    "        #用onnx中的helper函数的onnx_attr来解析onnx模型，读取出OP中的attr，\n",
    "        #唯一的区别在于不同的框架用不同的解析属性的方法\n",
    "        keepdims = onnx_attr(node, 'keepdims', 'i', default=1)\n",
    "        axis = onnx_attr(node, 'axis', 'i', default=0)\n",
    "        #制作成字典\n",
    "        attrs = {\n",
    "            'axis': axis,\n",
    "            'top_k': 1,\n",
    "            'keepdims': keepdims,\n",
    "            'remove_values_output': True\n",
    "        }\n",
    "        #将其当作图节点，传入图中对应的节点\n",
    "        ArgMinOp.update_node_stat(node, attrs)\n",
    "        return cls.enabled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018da663",
   "metadata": {},
   "outputs": [],
   "source": [
    "#将自定义算子MyRelu ，使用OPENVINO自带的RELU进行替换表示  1 VS 1\n",
    "core.add_extension(ov::frontend::OpExtension<>(\"Relu\", \"MyRelu\"));\n",
    "#或者\n",
    "core.add_extension(ov::frontend::OpExtension<>(ov::opset8::Relu , \"MyRelu\"));\n",
    "\n",
    "                                        \n",
    "core.add_extension(ov::frontend::OpExtension<CustomOperation>(\n",
    "    { \n",
    "        #实现属性的复制使得两个属性数据一样a==b，{“a”,“b”}\n",
    "    {\"attr1\", \"fw_attr1\"}, \n",
    "     {\"attr2\", \"fw_attr2\"} },\n",
    "    {}\n",
    "));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36a6ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <openvino/opsets/opset8.hpp>\n",
    "core.add_extension(ov::frontend::ConversionExtension(\n",
    "    \"ThresholdedReLU\",#ONNX中的算子名称\n",
    "    [](const ov::frontend::NodeContext& node) {\n",
    "        auto greater = std::make_shared<ov::opset8::Greater>(\n",
    "            node.get_input(0),\n",
    "            ov::opset8::Constant::create(ov::element::f32, {}, {node.get_attribute<float>(\"alpha\")}));\n",
    "        auto casted = std::make_shared<ov::opset8::Convert>(greater, ov::element::f32);\n",
    "        return ov::OutputVector{ std::make_shared<ov::opset8::Multiply>(node.get_input(0), casted) };\n",
    "    }));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303c2ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bbf703",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcbb563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebbd5e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b14bcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b679ac68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ada21aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
