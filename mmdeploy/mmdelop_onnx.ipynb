{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "706ab9c1",
   "metadata": {},
   "source": [
    "# 编译 MMDeploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f70ff80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#安装MMDEPLOY \n",
    "git clone https://github.com/open-mmlab/mmdeploy.git\n",
    "cd mmdeploy\n",
    "os.environ['MMDEPLOY_DIR']='/kaggle/working/mmdeploy'\n",
    "pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2c9115",
   "metadata": {},
   "outputs": [],
   "source": [
    "#编译自定义算子库，写完新算子要重新编译一次,这个也可以用\n",
    "mkdir -p build\n",
    "cd build\n",
    "cmake -DCMAKE_CXX_COMPILER=g++ -DMMDEPLOY_TARGET_BACKENDS=ort -DONNXRUNTIME_DIR=${ONNXRUNTIME_DIR} ..\n",
    "make -j$(nproc) \n",
    "make install\n",
    "#.so文件就在Lib文件夹下"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf21ec1",
   "metadata": {},
   "source": [
    "# 部署"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbd4e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /kaggle/working/\n",
    "!git clone https://github.com/open-mmlab/mmclassification.git\n",
    "%cd mmclassification\n",
    "!pip install -e . \n",
    "#保存路径\n",
    "!mkdir checkpoints\n",
    "#下载checkpoint\n",
    "\n",
    "!wget -c https://download.openmmlab.com/mmclassification/v0/vit/pretrain/vit-base-p16_3rdparty_pt-64xb64_in1k-224_20210928-02284250.pth \\\n",
    "      -O checkpoints/tmp.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9743a224",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ./tools/deploy.py \\\n",
    "    #这个是config里面的文件，看自己的训练要求看看要不要重写\n",
    "    ./configs/mmcls/classification_onnxruntime_static.py \\\n",
    "    #这个是模型文件\n",
    "    /kaggle/working/mmclassification/configs/resnet/resnet34_b16x8_cifar10.py \\\n",
    "    #这个是权重\n",
    "    /kaggle/working/mmclassification/checkpoints/tmp.pth \\\n",
    "    # 模型转换时，用做测试的图像或点云文件路径\n",
    "    /kaggle/working/mmclassification/demo/dog.jpg \\\n",
    "    --show \\\n",
    "    #默认cpu 对于TRT cuda:0\n",
    "    --device 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bfe044",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmcv\n",
    "from PIL import Image\n",
    "import onnxruntime\n",
    "import torchvision.transforms as transforms\n",
    "from mmcls.datasets import ImageNet\n",
    "import numpy as np\n",
    "pic_path='/kaggle/working/mmclassification/demo/bird.JPEG'\n",
    "\n",
    "#变形\n",
    "img=Image.open(pic_path)\n",
    "img_norm_cfg = dict(mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
    "resize = transforms.Resize([384,384])\n",
    "norm = transforms.Normalize(mean=img_norm_cfg['mean'],std=img_norm_cfg['std'])\n",
    "img = resize(img)\n",
    "\n",
    "#转成张量 ，预处理也可以在这里做\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "img_y = to_tensor(img)\n",
    "#img_y = norm(img_y)\n",
    "img_y.unsqueeze_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fb023f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#执行推断\n",
    "#因为是在onnxruntime上执行的，所以是将.onnx文件直接作为图传入，形成session\n",
    "ort_session = onnxruntime.InferenceSession('end2end.onnx')\n",
    "\n",
    "#这个是将输入放到正确的设备上\n",
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "# compute ONNX Runtime output prediction执行的方法\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(img_y)}#输入{'name':输入张量}\n",
    "ort_outs = ort_session.run(None, ort_inputs)#输出，其后要考虑对其进行后处理，生成最终的预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c79d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ImageNet.CLASSES\n",
    "prediction = np.argmax(ort_outs[0],axis=1)\n",
    "pre=label[int(prediction)]\n",
    "print(pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffda1cb8",
   "metadata": {},
   "source": [
    "# torch2onnx  \n",
    "   \n",
    "   ### 二选一"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d82322",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdeploy.apis import torch2onnx\n",
    "img = 'demo.jpg'\n",
    "work_dir = 'work_dir'\n",
    "save_file = 'fcos.onnx'\n",
    "deploy_cfg = ('configs/mmdet/detection/detection_onnxruntime_dynamic.py')\n",
    "model_cfg = ('mmdetection/configs/fcos/fcos_r50_caffe_fpn_gn-head_1x_coco.py')\n",
    "#model_checkpoint = ('checkpoints/fcos_r50_caffe_fpn_gn-head_1x_coco-821213aa.pth')\n",
    "#device = 'cpu'\n",
    "torch2onnx(img, work_dir, save_file, deploy_cfg, model_cfg, \n",
    "          # model_checkpoint, device\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4e413c",
   "metadata": {},
   "outputs": [],
   "source": [
    "python tools/torch2onnx.py \\\n",
    "    ${DEPLOY_CFG} \\\n",
    "    ${MODEL_CFG} \\\n",
    "    ${CHECKPOINT} \\\n",
    "    ${INPUT_IMG} \\\n",
    "    --work-dir ${WORK_DIR} \\\n",
    "    --device cpu \\\n",
    "    --log-level INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ab82f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用onnx文件转化到其他的平台，from_onnx执行命令行进行模型转化\n",
    "from mmdeploy.backend.tensorrt.utils import from_onnx\n",
    "\n",
    "engine = from_onnx(\n",
    "    'srcnn3.onnx',\n",
    "    'srcnn3',\n",
    "    input_shapes=dict(\n",
    "        input=dict(\n",
    "            min_shape=[1, 3, 256, 256],\n",
    "            opt_shape=[1, 3, 256, 256],\n",
    "            max_shape=[1, 3, 256, 256]),\n",
    "        factor=dict(\n",
    "            min_shape=[1, 1, 256, 256],\n",
    "            opt_shape=[1, 1, 512, 512],\n",
    "            max_shape=[1, 1, 1024, 1024])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b404e148",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmengine import Config\n",
    "from mmdeploy.apis.utils import build_task_processor\n",
    "import mmcv\n",
    "import cv2\n",
    "import torch\n",
    "from mmdeploy.utils import Backend, get_backend, get_input_shape\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3093f32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cfg= '/root/mmdetection-main/configs/fcos/fcos_r50-caffe_fpn_gn-head_1x_coco.py'\n",
    "checkpoint='/root/fcos_r50_caffe_fpn_gn-head_1x_coco-821213aa.pth'\n",
    "deploy_cfg = '/root/mmdeploy/configs/mmdet/detection/detection_onnxruntime_static.py'\n",
    "img = '/root/mmdetection-main/demo/demo.jpg'\n",
    "device='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91c25ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_processor = build_task_processor(Config.fromfile(model_cfg), Config.fromfile(deploy_cfg), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43acc9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = task_processor.build_backend_model(['/root/work_dir/FCOS.onnx'], data_preprocessor_updater=task_processor.\n",
    "                update_data_preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95a1293",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = get_input_shape(deploy_cfg)\n",
    "model_inputs, _ = task_processor.create_input(img, input_shape)\n",
    "with torch.no_grad():\n",
    "    result = model.test_step(model_inputs)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48fd91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = task_processor.get_visualizer('test','/root')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77383f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#如果有数据类名，要在外面把信息传递给可视化器\n",
    "# `DetLocalVisualizer().dataset_meta=xxx`,\n",
    "#{'classes'：[]，'palette'：[]}\n",
    "img=mmcv.imread(img)\n",
    "img = mmcv.imconvert(img, 'bgr', 'rgb')\n",
    "visualizer.add_datasample(\n",
    "    'test',\n",
    "    img,\n",
    "    data_sample=result,\n",
    "    draw_gt=False,\n",
    "    show=True,\n",
    "    # out_file='/root/test.jpg'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed16841",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = visualizer.get_image()\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a855cd5d",
   "metadata": {},
   "source": [
    "# 自定义算子的实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00d4aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#新建csrc/backend_ops/tensorrt/dynamic_resize\n",
    "#添加trt_dynamic_resize.hpp和trt_dynamic_resize.cpp两个文件\n",
    "#在dynamic_resize.hpp引入mmdeploy/csrc/backend_ops/tensorrt/common/trt_plugin_base.hpp\n",
    "\n",
    "#替换了TENSORRT原始的继承基类nvinfer1::IPluginV2DynamicExt和nvinfer1::IPluginCreator\n",
    "#class DynamicTRTResize : public TRTPluginBase{}\n",
    "#class DynamicTRTResizeCreator : public TRTPluginCreatorBase{}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e7f9549",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctypes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b0a8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dll = cdll.LoadLibrary(r'F:\\mmdeploy-main\\build\\lib\\Release\\mmdeploy_onnxruntime_ops.lib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8f288f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6c4453",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
